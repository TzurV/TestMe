{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Building_an_E2E_Speech_Recognition_model_using_BERT_4decoding",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4af4c331b314659a2e9b3baa9142dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13fc73ac27cd48d2b34d40ae165b14c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0194477ceda447cb84105d891a5cf8ca",
              "IPY_MODEL_c7acd4d193e94580a72808ae6efbd19e"
            ]
          }
        },
        "13fc73ac27cd48d2b34d40ae165b14c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0194477ceda447cb84105d891a5cf8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4d5b2d268e8b4bafbc6aa33f98baa3ca",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 346663984,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 346663984,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8796f5444d0447d5a0d1cdfb7491c8a8"
          }
        },
        "c7acd4d193e94580a72808ae6efbd19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f03428da6124ef78206e4b5d7cce131",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:09&lt;00:00, 36.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c249438ac8db436d87b2748f89c0b6cb"
          }
        },
        "4d5b2d268e8b4bafbc6aa33f98baa3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8796f5444d0447d5a0d1cdfb7491c8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f03428da6124ef78206e4b5d7cce131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c249438ac8db436d87b2748f89c0b6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TzurV/TestMe/blob/BERT-based-Decoder/Building_an_E2E_Speech_Recognition_model_using_BERT_4decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibD6bsRPl8Qu"
      },
      "source": [
        "# Building an end-to-end Speech Recognition model in PyTorch - [AssemblyAI](https://www.assemblyai.com/)\n",
        "\n",
        "Adding BERT based Decoder.\n",
        "Using Private Google drive as Drive for storing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVfrfGVmwR20"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmQCJFhIMHPr",
        "outputId": "439aefcd-4c3a-4b00-e0ce-5afba715cf41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "# use inline debuger\n",
        "from IPython.core.debugger import set_trace\n",
        "def bad_function(var):\n",
        "    set_trace()\n",
        "    return var\n",
        "bad_function(\"Mike\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-33-17a0bbede356>\u001b[0m(5)\u001b[0;36mbad_function\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      2 \u001b[0;31m\u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mbad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      6 \u001b[0;31m\u001b[0mbad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mike\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> n\n",
            "--Return--\n",
            "'Mike'\n",
            "> \u001b[0;32m<ipython-input-33-17a0bbede356>\u001b[0m(5)\u001b[0;36mbad_function\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      2 \u001b[0;31m\u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mbad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      6 \u001b[0;31m\u001b[0mbad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mike\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Mike'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "stream",
          "text": [
            "--Return--\n",
            "None\n",
            "> \u001b[0;32m<ipython-input-33-17a0bbede356>\u001b[0m(6)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      2 \u001b[0;31m\u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mbad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m----> 6 \u001b[0;31m\u001b[0mbad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mike\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhWH6jX-we8f",
        "outputId": "e7a2ab58-0722-4c05-a6cb-a8646a3792f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# mount Google Drive\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import re \n",
        "\n",
        "# mounting is required once every time you start this notebook  \n",
        "drive.mount('/content/gdrive')\n",
        "filesRootDirectory = \"/content/gdrive/My Drive/Colab_files/CTCmodels/\"\n",
        "\n",
        "# Set to True if you want to check that you have access to google drive\n",
        "if True:\n",
        "    # output file \n",
        "    # on PC it is located in <Google Drive directory>\\Colab_files\\CTCmodels\n",
        "    testOutputFileName = filesRootDirectory + \"testOutputFile.txt\"\n",
        "    testOutputFile = open(testOutputFileName,\"w\") \n",
        "    FORMAT = '%Y%m%d%H%M%S'\n",
        "    TodayDate = datetime.now().strftime(FORMAT)\n",
        "    print(f\" look for {TodayDate} in output file {testOutputFileName}.\")\n",
        "    testOutputFile.write(TodayDate+'\\n')\n",
        "    testOutputFile.close()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            " look for 20201002082853 in output file /content/gdrive/My Drive/Colab_files/CTCmodels/testOutputFile.txt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1fXgsDQmK09"
      },
      "source": [
        "## installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfN8o17Bdp2",
        "outputId": "107f11ed-e310-4dd2-c0a2-c83b4298992e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!pip install torchaudio==0.4.0 torch==1.4.0 comet-ml==3.0.2"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio==0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: comet-ml==3.0.2 in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.0.1)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (7.352.0)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (0.19.16)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (0.57.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (0.10.9)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.6.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet-ml==3.0.2) (2020.6.20)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet-ml==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet-ml==3.0.2) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSKHvy8DmOCQ"
      },
      "source": [
        "## Setting up your data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJs4Bk8FjjO"
      },
      "source": [
        "import os\n",
        "\n",
        "# The core class of Comet.ml is an Experiment, a specific run of a script that \n",
        "# generated a result such as training a model on a single set of hyper parameters. \n",
        "# An Experiment will automatically log scripts output (stdout/stderr), code, \n",
        "# and command line arguments on any script and for the supported libraries will\n",
        "#  also log hyper parameters, metrics and model configuration.\n",
        "from comet_ml import Experiment\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "    def int_to_char(self, index):\n",
        "        assert len(self.index_map)>int(index), \"Index exceeds map dimension \"\n",
        "        return self.index_map[int(index)]\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    # https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pad_sequence.html#torch-nn-utils-rnn-pad-sequence\n",
        "    # pad_sequence stacks a list of Tensors along a new dimension, and pads them to equal length. \n",
        "    # batch_first (bool, optional) – output will be in B x T x * if True, or in T x B x * otherwise\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "    arg_maxes = torch.argmax(output, dim=2)\n",
        "    decodes = []\n",
        "    targets = []\n",
        "    for i, args in enumerate(arg_maxes):\n",
        "        decode = []\n",
        "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "        for j, index in enumerate(args):\n",
        "            if index != blank_label:\n",
        "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
        "                    continue\n",
        "                decode.append(index.item())\n",
        "        decodes.append(text_transform.int_to_text(decode))\n",
        "    return decodes, targets\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XdSlhAQnDEA"
      },
      "source": [
        "## The Model\n",
        "Base of of Deep Speech 2 with some personal improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65H1-PCjm-FB"
      },
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuguNEzKnMOn"
      },
      "source": [
        "## The Training and Evaluating Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swaC12JeDhhc"
      },
      "source": [
        "def CreateModel(hparams, device):\n",
        "    ''' create model beased on hparams dictionary'''\n",
        "    return SpeechRecognitionModel(\n",
        "            hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "            hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "            ).to(device)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydkqGeOwnPGY"
      },
      "source": [
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    with experiment.train():\n",
        "        for batch_idx, _data in enumerate(train_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            loss.backward()\n",
        "\n",
        "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
        "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            iter_meter.step()\n",
        "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(spectrograms), data_len,\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter, experiment):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with experiment.test():\n",
        "        with torch.no_grad():\n",
        "            for i, _data in enumerate(test_loader):\n",
        "                spectrograms, labels, input_lengths, label_lengths = _data \n",
        "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "                output = model(spectrograms)  # (batch, time, n_class)\n",
        "                output = F.log_softmax(output, dim=2)\n",
        "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "                test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "                for j in range(len(decoded_preds)):\n",
        "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "    experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
        "    experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
        "    experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "\n",
        "\n",
        "def main(learning_rate=5e-4, batch_size=20, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\",\n",
        "        experiment=Experiment(api_key='dummy_key', disabled=True)):\n",
        "\n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    experiment.log_parameters(hparams)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    # local creation\n",
        "    if True:\n",
        "        model = SpeechRecognitionModel(\n",
        "            hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "            hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "            ).to(device)\n",
        "    else:\n",
        "        model = CreateModel(hparams, device)\n",
        "        \n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=28).to(device)\n",
        "    # torch.optim.lr_scheduler provides several methods to adjust the learning rate based on the number of epochs\n",
        "    #Sets the learning rate of each parameter group according to the 1cycle learning rate policy. \n",
        "    #The 1cycle policy anneals the learning rate from an initial learning rate to \n",
        "    # some maximum learning rate and then from that maximum learning rate to some \n",
        "    # minimum learning rate much lower than the initial learning rate. \n",
        "    # This policy was initially described in the paper Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates.\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter, experiment)\n",
        "\n",
        "    # return the final model\n",
        "    return model, hparams, device\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBGdkQSmW3a"
      },
      "source": [
        "## Setting up Comet\n",
        "If you have a comet account, fill in teh api key, project name and experiment name below. You can create an account at [comet.ml](comet.ml)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edo8shRBFt4V"
      },
      "source": [
        "comet_api_key = \"\" # add your api key here\n",
        "project_name = \"speechrecognition\"\n",
        "experiment_name = \"speechrecognition-colab\"\n",
        "\n",
        "if comet_api_key:\n",
        "  experiment = Experiment(api_key=comet_api_key, project_name=project_name, parse_args=False)\n",
        "  experiment.set_name(experiment_name)\n",
        "  experiment.display()\n",
        "else:\n",
        "  experiment = Experiment(api_key='dummy_key', disabled=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxRIb_WempDq"
      },
      "source": [
        "## GPU runtime\n",
        "If you are using a GPU runtime, this will let you know what GPU and how much memory is available. Adjust your batch_size depending on which GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlUSuAJwlzo8",
        "outputId": "baa8e721-9f53-4ee1-e1e3-a50c46dc6730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Oct  2 08:29:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    58W / 149W |   2188MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBT776XweV8R"
      },
      "source": [
        "## ORIGINAL code sequence "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1LsgT-m7HA_"
      },
      "source": [
        "def saveModel(model, outputFileName):\n",
        "    ''' Save NN model into  a file ''' \n",
        "    print(f\"saving {outputFileName}\")\n",
        "    torch.save(model, outputFileName)\n",
        "\n",
        "# update save/load as recommended here  \n",
        "# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "\n",
        "def saveModelAsDictionaryWithOptionalExtra(model, outputFileName, extra={}):\n",
        "    ''' Save NN model into  a file ''' \n",
        "    print(f\"saving {outputFileName}\")\n",
        "\n",
        "    torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                **extra,\n",
        "                }, outputFileName)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXvlWZeVpXfX"
      },
      "source": [
        "## Train\n",
        "this will download the data on first run and may take a while. \n",
        "\n",
        "If you have Comet.ml setup, you can start seeing your progress in the comet cell above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXAaegPIe6TF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7sRfxHNjiGw",
        "outputId": "a7546744-4890-4a75-cf8e-b8fed956eca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e4af4c331b314659a2e9b3baa9142dd8",
            "13fc73ac27cd48d2b34d40ae165b14c6",
            "0194477ceda447cb84105d891a5cf8ca",
            "c7acd4d193e94580a72808ae6efbd19e",
            "4d5b2d268e8b4bafbc6aa33f98baa3ca",
            "8796f5444d0447d5a0d1cdfb7491c8a8",
            "9f03428da6124ef78206e4b5d7cce131",
            "c249438ac8db436d87b2748f89c0b6cb"
          ]
        }
      },
      "source": [
        "# Phase I - to make sure things are working\n",
        "# short training cycle using the the test set for training and \n",
        "# evaluation \n",
        "learning_rate = 5e-4\n",
        "batch_size = 3\n",
        "epochs = 1\n",
        "libri_train_set = \"test-clean\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "model, hparams, device  = main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set, experiment)\n",
        "\n",
        "modelFileName = filesRootDirectory + \"PhaseImodel.pt\"\n",
        "#saveModel(model, modelFileName)\n",
        "saveModelAsDictionaryWithOptionalExtra(model, modelFileName, hparams)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4af4c331b314659a2e9b3baa9142dd8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=346663984.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SpeechRecognitionModel(\n",
            "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (rescnn_layers): Sequential(\n",
            "    (0): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (birnn_layers): Sequential(\n",
            "    (0): BidirectionalGRU(\n",
            "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): GELU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
            "  )\n",
            ")\n",
            "Num Model Parameters 23705373\n",
            "Train Epoch: 1 [0/2620 (0%)]\tLoss: 8.935959\n",
            "Train Epoch: 1 [300/2620 (11%)]\tLoss: 3.016985\n",
            "Train Epoch: 1 [600/2620 (23%)]\tLoss: 2.945797\n",
            "Train Epoch: 1 [900/2620 (34%)]\tLoss: 3.067736\n",
            "Train Epoch: 1 [1200/2620 (46%)]\tLoss: 2.977319\n",
            "Train Epoch: 1 [1500/2620 (57%)]\tLoss: 2.910932\n",
            "Train Epoch: 1 [1800/2620 (69%)]\tLoss: 2.990039\n",
            "Train Epoch: 1 [2100/2620 (80%)]\tLoss: 2.993558\n",
            "Train Epoch: 1 [2400/2620 (92%)]\tLoss: 2.901246\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.9192, Average CER: 1.000000 Average WER: 1.0000\n",
            "\n",
            "saving /content/gdrive/My Drive/Colab_files/CTCmodels/PhaseImodel.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYB9Myjjbs73"
      },
      "source": [
        "# Just recognition\n",
        "* load stored model\n",
        "* run recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtxGZQkzbA7k"
      },
      "source": [
        "if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "        \n",
        "test_url=\"test-clean\"\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmBcOJcVa1M_",
        "outputId": "6223612a-e8c2-4a9d-955d-baf81f6c71ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(type(test_dataset))\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "print(use_cuda)\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=5, # originaly 20\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "print(type(test_loader))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchaudio.datasets.librispeech.LIBRISPEECH'>\n",
            "True\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp4CICMOB4Sr",
        "outputId": "fba58eef-bbb6-4c2d-f012-5091e2de54fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "\n",
        "\n",
        "#print(model.state_dict())\n",
        "#hparams = {\n",
        "#        \"n_cnn_layers\": 3,\n",
        "#        \"n_rnn_layers\": 5,\n",
        "#        \"rnn_dim\": 512,\n",
        "#        \"n_class\": 29,\n",
        "#        \"n_feats\": 128,\n",
        "#        \"stride\":2,\n",
        "#        \"dropout\": 0.1,}\n",
        "#saveModelAsDictionaryWithOptionalExtra(model, modelFileName, extra=hparams)\n",
        "\n",
        "# test loading\n",
        "modelFileName = filesRootDirectory + \"PhaseImodel.pt\"\n",
        "checkpoint = torch.load(modelFileName)\n",
        "print(checkpoint.keys())\n",
        "\n",
        "model1 = CreateModel(checkpoint, device)\n",
        "model1.load_state_dict(checkpoint['model_state_dict'])\n",
        "model1.eval()\n",
        "\n",
        "criterion1 = nn.CTCLoss(blank=28).to(device)\n",
        "iter_meter = IterMeter()\n",
        "test(model1, device, test_loader, criterion1, 0, iter_meter, experiment=Experiment(api_key='dummy_key', disabled=True))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['model_state_dict', 'n_cnn_layers', 'n_rnn_layers', 'rnn_dim', 'n_class', 'n_feats', 'stride', 'dropout', 'learning_rate', 'batch_size', 'epochs'])\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.9232, Average CER: 1.000000 Average WER: 1.0000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toFx1uY0veRq",
        "outputId": "d14af4e4-cff2-4d69-b641-21139c1a4a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Understand GreedyDecoder output\n",
        "# stops for debugging on errors (?)\n",
        "#%debug\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, _data in enumerate(test_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        output = model1(spectrograms)  # (batch, time, n_class)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "        print(f\"#Inference output #dim={output.dim()}, {output.size()}, {output.transpose(0, 1).size()}\")\n",
        "        print(f\"# reference text: {text_transform.int_to_text(labels[i][:label_lengths[i]].tolist())}\")\n",
        "        #print(labels[i][:label_lengths[i]])\n",
        "        \n",
        "        for jj in range(label_lengths[i]):\n",
        "            outputArgmax = int(torch.argmax(output[jj][0][:]))\n",
        "            print(output[jj][0][:], outputArgmax)\n",
        "            #print(text_transform.int_to_char(outputArgmax))\n",
        "            \n",
        "\n",
        "        decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "        print(type(decoded_preds), len(decoded_preds), type(decoded_targets))\n",
        "\n",
        "\n",
        "        print(f\"# predicted text: {decoded_targets[0]}\")\n",
        "\n",
        "\n",
        "        break"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#Inference output #dim=3, torch.Size([468, 5, 29]), torch.Size([5, 468, 29])\n",
            "# reference text: kenneth and beth refrained from telling the other girls or uncle john of old will rogers's visit but they got mister watson in the library and questioned him closely about the penalty for forging a check\n",
            "tensor([-7.0685, -2.9670, -3.9111, -5.5368, -4.9965, -4.5809, -3.2602, -5.1515,\n",
            "        -5.3899, -3.9001, -3.8154, -8.1137, -6.2814, -4.4313, -5.0327, -3.9962,\n",
            "        -3.8489, -5.5376, -8.2526, -4.1746, -4.0268, -3.5308, -4.8357, -6.0058,\n",
            "        -5.0688, -7.8690, -5.2966, -8.6188, -0.4057], device='cuda:0') 28\n",
            "tensor([-7.0935, -2.9391, -3.9154, -5.5545, -5.0106, -4.5855, -3.2732, -5.1558,\n",
            "        -5.3912, -3.9347, -3.8400, -8.1341, -6.2910, -4.4396, -5.0475, -3.9981,\n",
            "        -3.8534, -5.5566, -8.2733, -4.1798, -4.0356, -3.5524, -4.8445, -6.0211,\n",
            "        -5.0939, -7.8961, -5.3107, -8.6469, -0.4024], device='cuda:0') 28\n",
            "tensor([-7.1130, -2.9027, -3.9164, -5.5665, -5.0206, -4.5847, -3.2835, -5.1542,\n",
            "        -5.3859, -3.9718, -3.8641, -8.1452, -6.2921, -4.4430, -5.0590, -3.9962,\n",
            "        -3.8548, -5.5713, -8.2855, -4.1817, -4.0403, -3.5750, -4.8483, -6.0304,\n",
            "        -5.1143, -7.9177, -5.3179, -8.6655, -0.4010], device='cuda:0') 28\n",
            "tensor([-7.1193, -2.8897, -3.9165, -5.5704, -5.0227, -4.5842, -3.2856, -5.1530,\n",
            "        -5.3834, -3.9839, -3.8718, -8.1494, -6.2917, -4.4440, -5.0626, -3.9948,\n",
            "        -3.8550, -5.5764, -8.2904, -4.1822, -4.0412, -3.5827, -4.8497, -6.0337,\n",
            "        -5.1201, -7.9250, -5.3191, -8.6719, -0.4009], device='cuda:0') 28\n",
            "tensor([-7.1276, -2.8694, -3.9160, -5.5747, -5.0257, -4.5827, -3.2886, -5.1500,\n",
            "        -5.3777, -4.0017, -3.8826, -8.1536, -6.2895, -4.4440, -5.0677, -3.9920,\n",
            "        -3.8546, -5.5828, -8.2952, -4.1825, -4.0418, -3.5941, -4.8511, -6.0373,\n",
            "        -5.1270, -7.9343, -5.3200, -8.6790, -0.4010], device='cuda:0') 28\n",
            "tensor([-7.1305, -2.8579, -3.9151, -5.5762, -5.0270, -4.5812, -3.2903, -5.1480,\n",
            "        -5.3741, -4.0111, -3.8883, -8.1544, -6.2874, -4.4436, -5.0693, -3.9900,\n",
            "        -3.8543, -5.5855, -8.2964, -4.1822, -4.0422, -3.6000, -4.8515, -6.0383,\n",
            "        -5.1304, -7.9377, -5.3196, -8.6812, -0.4013], device='cuda:0') 28\n",
            "tensor([-7.1322, -2.8496, -3.9144, -5.5766, -5.0280, -4.5801, -3.2913, -5.1458,\n",
            "        -5.3711, -4.0181, -3.8924, -8.1549, -6.2855, -4.4433, -5.0702, -3.9885,\n",
            "        -3.8541, -5.5867, -8.2970, -4.1815, -4.0423, -3.6043, -4.8511, -6.0384,\n",
            "        -5.1325, -7.9399, -5.3190, -8.6821, -0.4016], device='cuda:0') 28\n",
            "tensor([-7.1331, -2.8456, -3.9141, -5.5769, -5.0288, -4.5793, -3.2922, -5.1452,\n",
            "        -5.3696, -4.0216, -3.8945, -8.1547, -6.2843, -4.4437, -5.0704, -3.9877,\n",
            "        -3.8543, -5.5873, -8.2971, -4.1812, -4.0421, -3.6064, -4.8509, -6.0385,\n",
            "        -5.1338, -7.9405, -5.3190, -8.6823, -0.4017], device='cuda:0') 28\n",
            "tensor([-7.1356, -2.8309, -3.9128, -5.5777, -5.0306, -4.5766, -3.2949, -5.1419,\n",
            "        -5.3644, -4.0345, -3.9020, -8.1529, -6.2805, -4.4432, -5.0717, -3.9847,\n",
            "        -3.8536, -5.5890, -8.2966, -4.1800, -4.0418, -3.6138, -4.8508, -6.0389,\n",
            "        -5.1385, -7.9426, -5.3188, -8.6824, -0.4022], device='cuda:0') 28\n",
            "tensor([-7.1385, -2.8078, -3.9100, -5.5787, -5.0331, -4.5720, -3.2992, -5.1361,\n",
            "        -5.3556, -4.0551, -3.9139, -8.1491, -6.2732, -4.4422, -5.0734, -3.9795,\n",
            "        -3.8519, -5.5909, -8.2953, -4.1780, -4.0411, -3.6252, -4.8506, -6.0391,\n",
            "        -5.1455, -7.9449, -5.3177, -8.6811, -0.4031], device='cuda:0') 28\n",
            "tensor([-7.1427, -2.7799, -3.9067, -5.5799, -5.0366, -4.5671, -3.3048, -5.1300,\n",
            "        -5.3466, -4.0802, -3.9284, -8.1453, -6.2655, -4.4415, -5.0745, -3.9730,\n",
            "        -3.8496, -5.5927, -8.2945, -4.1760, -4.0402, -3.6389, -4.8510, -6.0390,\n",
            "        -5.1547, -7.9481, -5.3168, -8.6797, -0.4042], device='cuda:0') 28\n",
            "tensor([-7.1483, -2.7484, -3.9030, -5.5818, -5.0419, -4.5625, -3.3109, -5.1244,\n",
            "        -5.3383, -4.1082, -3.9444, -8.1432, -6.2587, -4.4407, -5.0771, -3.9652,\n",
            "        -3.8472, -5.5955, -8.2966, -4.1744, -4.0395, -3.6545, -4.8535, -6.0401,\n",
            "        -5.1663, -7.9539, -5.3166, -8.6805, -0.4055], device='cuda:0') 28\n",
            "tensor([-7.1564, -2.7159, -3.8998, -5.5850, -5.0484, -4.5590, -3.3172, -5.1187,\n",
            "        -5.3311, -4.1369, -3.9611, -8.1445, -6.2537, -4.4403, -5.0810, -3.9565,\n",
            "        -3.8449, -5.5998, -8.3026, -4.1733, -4.0385, -3.6717, -4.8574, -6.0431,\n",
            "        -5.1793, -7.9643, -5.3166, -8.6844, -0.4069], device='cuda:0') 28\n",
            "tensor([-7.1631, -2.6923, -3.8976, -5.5885, -5.0523, -4.5566, -3.3213, -5.1145,\n",
            "        -5.3250, -4.1571, -3.9728, -8.1466, -6.2499, -4.4400, -5.0843, -3.9505,\n",
            "        -3.8434, -5.6038, -8.3075, -4.1726, -4.0381, -3.6839, -4.8603, -6.0453,\n",
            "        -5.1885, -7.9729, -5.3164, -8.6880, -0.4079], device='cuda:0') 28\n",
            "tensor([-7.1695, -2.6656, -3.8950, -5.5920, -5.0559, -4.5534, -3.3251, -5.1089,\n",
            "        -5.3170, -4.1791, -3.9855, -8.1478, -6.2445, -4.4393, -5.0878, -3.9433,\n",
            "        -3.8411, -5.6075, -8.3126, -4.1710, -4.0375, -3.6971, -4.8630, -6.0474,\n",
            "        -5.1970, -7.9814, -5.3154, -8.6908, -0.4095], device='cuda:0') 28\n",
            "tensor([-7.1747, -2.6468, -3.8932, -5.5951, -5.0588, -4.5517, -3.3273, -5.1058,\n",
            "        -5.3125, -4.1936, -3.9940, -8.1500, -6.2418, -4.4388, -5.0903, -3.9378,\n",
            "        -3.8396, -5.6109, -8.3176, -4.1703, -4.0374, -3.7062, -4.8654, -6.0495,\n",
            "        -5.2027, -7.9891, -5.3159, -8.6946, -0.4107], device='cuda:0') 28\n",
            "tensor([-7.1760, -2.6402, -3.8926, -5.5958, -5.0597, -4.5511, -3.3281, -5.1044,\n",
            "        -5.3106, -4.1983, -3.9967, -8.1503, -6.2406, -4.4385, -5.0908, -3.9357,\n",
            "        -3.8390, -5.6122, -8.3187, -4.1699, -4.0373, -3.7090, -4.8658, -6.0496,\n",
            "        -5.2046, -7.9913, -5.3157, -8.6958, -0.4112], device='cuda:0') 28\n",
            "tensor([-7.1775, -2.6352, -3.8920, -5.5965, -5.0605, -4.5502, -3.3287, -5.1034,\n",
            "        -5.3095, -4.2022, -3.9988, -8.1508, -6.2403, -4.4381, -5.0914, -3.9341,\n",
            "        -3.8387, -5.6134, -8.3202, -4.1695, -4.0373, -3.7113, -4.8665, -6.0501,\n",
            "        -5.2061, -7.9934, -5.3160, -8.6969, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1779, -2.6339, -3.8920, -5.5967, -5.0610, -4.5500, -3.3287, -5.1031,\n",
            "        -5.3093, -4.2030, -3.9995, -8.1511, -6.2404, -4.4382, -5.0917, -3.9337,\n",
            "        -3.8386, -5.6140, -8.3210, -4.1698, -4.0373, -3.7121, -4.8668, -6.0506,\n",
            "        -5.2068, -7.9942, -5.3160, -8.6973, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1784, -2.6324, -3.8919, -5.5970, -5.0613, -4.5498, -3.3287, -5.1030,\n",
            "        -5.3092, -4.2040, -4.0001, -8.1513, -6.2402, -4.4382, -5.0917, -3.9332,\n",
            "        -3.8384, -5.6142, -8.3218, -4.1697, -4.0374, -3.7126, -4.8670, -6.0510,\n",
            "        -5.2071, -7.9950, -5.3160, -8.6978, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1788, -2.6311, -3.8918, -5.5972, -5.0618, -4.5497, -3.3289, -5.1026,\n",
            "        -5.3091, -4.2050, -4.0007, -8.1515, -6.2401, -4.4381, -5.0918, -3.9327,\n",
            "        -3.8382, -5.6145, -8.3224, -4.1697, -4.0373, -3.7131, -4.8672, -6.0511,\n",
            "        -5.2075, -7.9958, -5.3164, -8.6981, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1790, -2.6309, -3.8917, -5.5971, -5.0620, -4.5496, -3.3291, -5.1025,\n",
            "        -5.3088, -4.2052, -4.0007, -8.1513, -6.2403, -4.4380, -5.0918, -3.9325,\n",
            "        -3.8380, -5.6146, -8.3224, -4.1695, -4.0371, -3.7132, -4.8672, -6.0513,\n",
            "        -5.2076, -7.9957, -5.3165, -8.6981, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1797, -2.6300, -3.8919, -5.5975, -5.0624, -4.5497, -3.3291, -5.1027,\n",
            "        -5.3087, -4.2058, -4.0012, -8.1522, -6.2403, -4.4381, -5.0921, -3.9322,\n",
            "        -3.8382, -5.6149, -8.3230, -4.1696, -4.0371, -3.7137, -4.8675, -6.0516,\n",
            "        -5.2079, -7.9964, -5.3169, -8.6987, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1803, -2.6289, -3.8920, -5.5981, -5.0627, -4.5499, -3.3293, -5.1026,\n",
            "        -5.3088, -4.2067, -4.0017, -8.1528, -6.2405, -4.4381, -5.0925, -3.9321,\n",
            "        -3.8385, -5.6155, -8.3235, -4.1696, -4.0374, -3.7143, -4.8679, -6.0517,\n",
            "        -5.2086, -7.9972, -5.3173, -8.6996, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1806, -2.6306, -3.8926, -5.5986, -5.0633, -4.5502, -3.3296, -5.1034,\n",
            "        -5.3095, -4.2064, -4.0016, -8.1536, -6.2412, -4.4385, -5.0928, -3.9331,\n",
            "        -3.8389, -5.6160, -8.3236, -4.1703, -4.0378, -3.7143, -4.8686, -6.0521,\n",
            "        -5.2093, -7.9973, -5.3182, -8.6999, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1809, -2.6301, -3.8926, -5.5987, -5.0636, -4.5501, -3.3296, -5.1033,\n",
            "        -5.3095, -4.2067, -4.0018, -8.1538, -6.2411, -4.4386, -5.0929, -3.9330,\n",
            "        -3.8389, -5.6161, -8.3240, -4.1702, -4.0377, -3.7143, -4.8686, -6.0522,\n",
            "        -5.2096, -7.9975, -5.3181, -8.7002, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1804, -2.6291, -3.8924, -5.5985, -5.0631, -4.5499, -3.3293, -5.1028,\n",
            "        -5.3089, -4.2070, -4.0022, -8.1529, -6.2402, -4.4384, -5.0926, -3.9325,\n",
            "        -3.8386, -5.6155, -8.3234, -4.1697, -4.0376, -3.7142, -4.8682, -6.0519,\n",
            "        -5.2093, -7.9970, -5.3173, -8.6995, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1805, -2.6268, -3.8921, -5.5988, -5.0635, -4.5496, -3.3295, -5.1022,\n",
            "        -5.3084, -4.2084, -4.0030, -8.1526, -6.2398, -4.4383, -5.0926, -3.9317,\n",
            "        -3.8383, -5.6159, -8.3238, -4.1695, -4.0378, -3.7151, -4.8682, -6.0520,\n",
            "        -5.2098, -7.9977, -5.3170, -8.6997, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1806, -2.6254, -3.8919, -5.5989, -5.0635, -4.5492, -3.3296, -5.1021,\n",
            "        -5.3080, -4.2091, -4.0032, -8.1527, -6.2398, -4.4380, -5.0927, -3.9311,\n",
            "        -3.8382, -5.6161, -8.3242, -4.1693, -4.0378, -3.7155, -4.8685, -6.0523,\n",
            "        -5.2094, -7.9981, -5.3168, -8.6998, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1815, -2.6245, -3.8919, -5.5993, -5.0638, -4.5494, -3.3299, -5.1027,\n",
            "        -5.3083, -4.2094, -4.0033, -8.1538, -6.2402, -4.4380, -5.0929, -3.9306,\n",
            "        -3.8382, -5.6167, -8.3254, -4.1695, -4.0378, -3.7161, -4.8689, -6.0530,\n",
            "        -5.2095, -7.9994, -5.3170, -8.7009, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1811, -2.6257, -3.8919, -5.5991, -5.0636, -4.5496, -3.3299, -5.1029,\n",
            "        -5.3085, -4.2086, -4.0028, -8.1535, -6.2405, -4.4380, -5.0929, -3.9307,\n",
            "        -3.8383, -5.6166, -8.3252, -4.1695, -4.0375, -3.7158, -4.8687, -6.0528,\n",
            "        -5.2092, -7.9988, -5.3170, -8.7008, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1812, -2.6257, -3.8919, -5.5987, -5.0637, -4.5496, -3.3299, -5.1029,\n",
            "        -5.3086, -4.2086, -4.0028, -8.1535, -6.2404, -4.4379, -5.0929, -3.9305,\n",
            "        -3.8384, -5.6167, -8.3252, -4.1694, -4.0375, -3.7157, -4.8686, -6.0529,\n",
            "        -5.2092, -7.9987, -5.3169, -8.7006, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1812, -2.6252, -3.8919, -5.5985, -5.0638, -4.5495, -3.3299, -5.1028,\n",
            "        -5.3084, -4.2089, -4.0030, -8.1536, -6.2402, -4.4379, -5.0928, -3.9302,\n",
            "        -3.8384, -5.6167, -8.3253, -4.1693, -4.0376, -3.7157, -4.8686, -6.0527,\n",
            "        -5.2093, -7.9988, -5.3169, -8.7007, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1808, -2.6250, -3.8920, -5.5981, -5.0637, -4.5491, -3.3300, -5.1025,\n",
            "        -5.3082, -4.2090, -4.0032, -8.1531, -6.2398, -4.4378, -5.0928, -3.9302,\n",
            "        -3.8384, -5.6167, -8.3245, -4.1693, -4.0376, -3.7157, -4.8686, -6.0526,\n",
            "        -5.2095, -7.9985, -5.3167, -8.7000, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1814, -2.6247, -3.8919, -5.5986, -5.0640, -4.5494, -3.3300, -5.1027,\n",
            "        -5.3086, -4.2094, -4.0036, -8.1535, -6.2401, -4.4380, -5.0930, -3.9303,\n",
            "        -3.8384, -5.6170, -8.3252, -4.1694, -4.0377, -3.7160, -4.8688, -6.0529,\n",
            "        -5.2099, -7.9992, -5.3171, -8.7006, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1811, -2.6240, -3.8917, -5.5984, -5.0639, -4.5490, -3.3299, -5.1020,\n",
            "        -5.3082, -4.2100, -4.0038, -8.1530, -6.2397, -4.4379, -5.0929, -3.9302,\n",
            "        -3.8381, -5.6167, -8.3250, -4.1691, -4.0376, -3.7160, -4.8685, -6.0525,\n",
            "        -5.2098, -7.9990, -5.3170, -8.7002, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1807, -2.6246, -3.8915, -5.5983, -5.0635, -4.5488, -3.3298, -5.1018,\n",
            "        -5.3079, -4.2095, -4.0035, -8.1526, -6.2396, -4.4378, -5.0927, -3.9305,\n",
            "        -3.8380, -5.6163, -8.3245, -4.1690, -4.0374, -3.7156, -4.8681, -6.0521,\n",
            "        -5.2094, -7.9984, -5.3166, -8.6997, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1796, -2.6269, -3.8914, -5.5975, -5.0626, -4.5487, -3.3293, -5.1017,\n",
            "        -5.3078, -4.2078, -4.0026, -8.1517, -6.2393, -4.4376, -5.0921, -3.9313,\n",
            "        -3.8381, -5.6153, -8.3234, -4.1689, -4.0372, -3.7144, -4.8674, -6.0514,\n",
            "        -5.2083, -7.9968, -5.3162, -8.6982, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1782, -2.6288, -3.8913, -5.5968, -5.0618, -4.5485, -3.3289, -5.1013,\n",
            "        -5.3075, -4.2064, -4.0017, -8.1503, -6.2388, -4.4374, -5.0915, -3.9319,\n",
            "        -3.8380, -5.6142, -8.3221, -4.1688, -4.0369, -3.7134, -4.8666, -6.0507,\n",
            "        -5.2072, -7.9950, -5.3154, -8.6968, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1783, -2.6292, -3.8915, -5.5968, -5.0615, -4.5487, -3.3287, -5.1013,\n",
            "        -5.3076, -4.2060, -4.0016, -8.1504, -6.2389, -4.4375, -5.0914, -3.9322,\n",
            "        -3.8381, -5.6140, -8.3221, -4.1688, -4.0370, -3.7133, -4.8668, -6.0508,\n",
            "        -5.2070, -7.9949, -5.3154, -8.6969, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1789, -2.6299, -3.8920, -5.5972, -5.0616, -4.5490, -3.3288, -5.1017,\n",
            "        -5.3080, -4.2059, -4.0017, -8.1510, -6.2398, -4.4377, -5.0915, -3.9324,\n",
            "        -3.8384, -5.6146, -8.3228, -4.1694, -4.0372, -3.7137, -4.8674, -6.0513,\n",
            "        -5.2074, -7.9956, -5.3159, -8.6976, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1797, -2.6340, -3.8932, -5.5979, -5.0624, -4.5502, -3.3292, -5.1033,\n",
            "        -5.3103, -4.2043, -4.0008, -8.1528, -6.2423, -4.4386, -5.0919, -3.9340,\n",
            "        -3.8393, -5.6156, -8.3238, -4.1705, -4.0377, -3.7132, -4.8683, -6.0523,\n",
            "        -5.2082, -7.9961, -5.3174, -8.6988, -0.4112], device='cuda:0') 28\n",
            "tensor([-7.1799, -2.6400, -3.8945, -5.5982, -5.0630, -4.5515, -3.3293, -5.1057,\n",
            "        -5.3132, -4.2005, -3.9992, -8.1544, -6.2447, -4.4397, -5.0922, -3.9359,\n",
            "        -3.8403, -5.6160, -8.3243, -4.1716, -4.0379, -3.7113, -4.8687, -6.0531,\n",
            "        -5.2082, -7.9955, -5.3190, -8.6994, -0.4105], device='cuda:0') 28\n",
            "tensor([-7.1793, -2.6424, -3.8946, -5.5981, -5.0628, -4.5519, -3.3290, -5.1064,\n",
            "        -5.3138, -4.1990, -3.9983, -8.1544, -6.2451, -4.4401, -5.0922, -3.9368,\n",
            "        -3.8404, -5.6154, -8.3238, -4.1717, -4.0380, -3.7102, -4.8684, -6.0528,\n",
            "        -5.2079, -7.9944, -5.3191, -8.6990, -0.4103], device='cuda:0') 28\n",
            "tensor([-7.1792, -2.6389, -3.8938, -5.5980, -5.0624, -4.5512, -3.3292, -5.1053,\n",
            "        -5.3123, -4.2013, -3.9992, -8.1537, -6.2433, -4.4396, -5.0923, -3.9357,\n",
            "        -3.8397, -5.6153, -8.3232, -4.1710, -4.0377, -3.7112, -4.8678, -6.0522,\n",
            "        -5.2080, -7.9945, -5.3183, -8.6984, -0.4107], device='cuda:0') 28\n",
            "tensor([-7.1792, -2.6344, -3.8930, -5.5980, -5.0622, -4.5504, -3.3292, -5.1038,\n",
            "        -5.3104, -4.2039, -4.0005, -8.1528, -6.2414, -4.4389, -5.0926, -3.9345,\n",
            "        -3.8390, -5.6151, -8.3226, -4.1702, -4.0375, -3.7124, -4.8676, -6.0516,\n",
            "        -5.2083, -7.9949, -5.3174, -8.6981, -0.4112], device='cuda:0') 28\n",
            "tensor([-7.1794, -2.6300, -3.8923, -5.5980, -5.0625, -4.5497, -3.3292, -5.1026,\n",
            "        -5.3090, -4.2063, -4.0018, -8.1518, -6.2402, -4.4384, -5.0927, -3.9330,\n",
            "        -3.8385, -5.6150, -8.3226, -4.1697, -4.0374, -3.7138, -4.8677, -6.0517,\n",
            "        -5.2088, -7.9959, -5.3168, -8.6982, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1796, -2.6267, -3.8918, -5.5980, -5.0629, -4.5491, -3.3294, -5.1018,\n",
            "        -5.3082, -4.2083, -4.0029, -8.1511, -6.2394, -4.4379, -5.0926, -3.9316,\n",
            "        -3.8381, -5.6153, -8.3228, -4.1692, -4.0374, -3.7148, -4.8678, -6.0517,\n",
            "        -5.2093, -7.9968, -5.3165, -8.6986, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1804, -2.6247, -3.8917, -5.5983, -5.0636, -4.5488, -3.3298, -5.1016,\n",
            "        -5.3080, -4.2097, -4.0037, -8.1514, -6.2392, -4.4379, -5.0929, -3.9309,\n",
            "        -3.8380, -5.6160, -8.3233, -4.1691, -4.0374, -3.7157, -4.8680, -6.0521,\n",
            "        -5.2100, -7.9976, -5.3169, -8.6993, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1804, -2.6252, -3.8917, -5.5981, -5.0636, -4.5487, -3.3297, -5.1017,\n",
            "        -5.3079, -4.2096, -4.0035, -8.1515, -6.2394, -4.4379, -5.0928, -3.9309,\n",
            "        -3.8380, -5.6161, -8.3234, -4.1693, -4.0374, -3.7159, -4.8681, -6.0522,\n",
            "        -5.2099, -7.9977, -5.3171, -8.6992, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1800, -2.6271, -3.8919, -5.5978, -5.0630, -4.5491, -3.3295, -5.1020,\n",
            "        -5.3080, -4.2085, -4.0028, -8.1516, -6.2397, -4.4379, -5.0928, -3.9315,\n",
            "        -3.8383, -5.6159, -8.3231, -4.1696, -4.0374, -3.7152, -4.8679, -6.0520,\n",
            "        -5.2094, -7.9972, -5.3170, -8.6989, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1800, -2.6297, -3.8922, -5.5979, -5.0626, -4.5496, -3.3294, -5.1025,\n",
            "        -5.3086, -4.2071, -4.0020, -8.1523, -6.2403, -4.4382, -5.0927, -3.9324,\n",
            "        -3.8387, -5.6158, -8.3232, -4.1700, -4.0374, -3.7145, -4.8678, -6.0517,\n",
            "        -5.2090, -7.9969, -5.3173, -8.6988, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1790, -2.6326, -3.8924, -5.5975, -5.0618, -4.5496, -3.3289, -5.1026,\n",
            "        -5.3088, -4.2050, -4.0010, -8.1520, -6.2404, -4.4384, -5.0921, -3.9336,\n",
            "        -3.8387, -5.6149, -8.3226, -4.1697, -4.0372, -3.7130, -4.8671, -6.0513,\n",
            "        -5.2080, -7.9952, -5.3171, -8.6978, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1790, -2.6321, -3.8923, -5.5976, -5.0618, -4.5495, -3.3288, -5.1024,\n",
            "        -5.3087, -4.2052, -4.0012, -8.1520, -6.2401, -4.4383, -5.0921, -3.9336,\n",
            "        -3.8385, -5.6148, -8.3227, -4.1696, -4.0371, -3.7131, -4.8671, -6.0512,\n",
            "        -5.2080, -7.9952, -5.3168, -8.6979, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1795, -2.6300, -3.8922, -5.5976, -5.0623, -4.5496, -3.3291, -5.1022,\n",
            "        -5.3083, -4.2064, -4.0018, -8.1520, -6.2399, -4.4382, -5.0922, -3.9327,\n",
            "        -3.8383, -5.6151, -8.3233, -4.1695, -4.0372, -3.7138, -4.8673, -6.0516,\n",
            "        -5.2083, -7.9963, -5.3167, -8.6983, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1797, -2.6284, -3.8920, -5.5976, -5.0625, -4.5493, -3.3292, -5.1019,\n",
            "        -5.3080, -4.2071, -4.0024, -8.1519, -6.2396, -4.4380, -5.0921, -3.9320,\n",
            "        -3.8381, -5.6149, -8.3235, -4.1692, -4.0371, -3.7142, -4.8675, -6.0518,\n",
            "        -5.2084, -7.9969, -5.3165, -8.6985, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1804, -2.6260, -3.8916, -5.5979, -5.0632, -4.5490, -3.3294, -5.1016,\n",
            "        -5.3078, -4.2086, -4.0032, -8.1519, -6.2394, -4.4377, -5.0923, -3.9312,\n",
            "        -3.8379, -5.6152, -8.3237, -4.1688, -4.0373, -3.7148, -4.8678, -6.0521,\n",
            "        -5.2088, -7.9976, -5.3166, -8.6992, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1810, -2.6240, -3.8917, -5.5982, -5.0641, -4.5487, -3.3300, -5.1017,\n",
            "        -5.3078, -4.2101, -4.0039, -8.1523, -6.2394, -4.4376, -5.0928, -3.9302,\n",
            "        -3.8379, -5.6162, -8.3243, -4.1688, -4.0375, -3.7158, -4.8686, -6.0525,\n",
            "        -5.2097, -7.9988, -5.3168, -8.7000, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1814, -2.6240, -3.8918, -5.5981, -5.0646, -4.5491, -3.3302, -5.1020,\n",
            "        -5.3082, -4.2101, -4.0037, -8.1528, -6.2397, -4.4377, -5.0931, -3.9302,\n",
            "        -3.8378, -5.6165, -8.3247, -4.1691, -4.0376, -3.7159, -4.8687, -6.0530,\n",
            "        -5.2097, -7.9994, -5.3174, -8.7001, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1815, -2.6243, -3.8918, -5.5980, -5.0647, -4.5492, -3.3304, -5.1022,\n",
            "        -5.3082, -4.2099, -4.0037, -8.1528, -6.2398, -4.4376, -5.0930, -3.9300,\n",
            "        -3.8379, -5.6166, -8.3246, -4.1690, -4.0375, -3.7160, -4.8687, -6.0529,\n",
            "        -5.2096, -7.9993, -5.3175, -8.7002, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1813, -2.6249, -3.8918, -5.5980, -5.0645, -4.5493, -3.3304, -5.1024,\n",
            "        -5.3082, -4.2095, -4.0035, -8.1527, -6.2398, -4.4376, -5.0930, -3.9301,\n",
            "        -3.8380, -5.6167, -8.3242, -4.1691, -4.0376, -3.7158, -4.8688, -6.0526,\n",
            "        -5.2095, -7.9988, -5.3175, -8.6999, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1812, -2.6259, -3.8919, -5.5981, -5.0639, -4.5497, -3.3301, -5.1026,\n",
            "        -5.3084, -4.2088, -4.0031, -8.1526, -6.2401, -4.4378, -5.0929, -3.9305,\n",
            "        -3.8381, -5.6164, -8.3242, -4.1695, -4.0376, -3.7154, -4.8686, -6.0525,\n",
            "        -5.2091, -7.9987, -5.3174, -8.6997, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1807, -2.6271, -3.8920, -5.5980, -5.0633, -4.5498, -3.3298, -5.1026,\n",
            "        -5.3084, -4.2082, -4.0027, -8.1524, -6.2401, -4.4380, -5.0928, -3.9311,\n",
            "        -3.8382, -5.6160, -8.3240, -4.1697, -4.0376, -3.7149, -4.8684, -6.0522,\n",
            "        -5.2088, -7.9982, -5.3173, -8.6994, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1801, -2.6287, -3.8923, -5.5978, -5.0628, -4.5497, -3.3296, -5.1025,\n",
            "        -5.3085, -4.2073, -4.0022, -8.1522, -6.2403, -4.4380, -5.0928, -3.9319,\n",
            "        -3.8385, -5.6159, -8.3234, -4.1699, -4.0376, -3.7144, -4.8680, -6.0518,\n",
            "        -5.2088, -7.9976, -5.3173, -8.6991, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1791, -2.6314, -3.8924, -5.5974, -5.0620, -4.5498, -3.3293, -5.1028,\n",
            "        -5.3089, -4.2056, -4.0011, -8.1516, -6.2404, -4.4381, -5.0924, -3.9330,\n",
            "        -3.8387, -5.6151, -8.3225, -4.1699, -4.0375, -3.7133, -4.8674, -6.0512,\n",
            "        -5.2080, -7.9960, -5.3169, -8.6979, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1786, -2.6334, -3.8924, -5.5973, -5.0615, -4.5499, -3.3290, -5.1030,\n",
            "        -5.3092, -4.2044, -4.0004, -8.1515, -6.2406, -4.4383, -5.0921, -3.9339,\n",
            "        -3.8388, -5.6146, -8.3221, -4.1699, -4.0374, -3.7124, -4.8671, -6.0510,\n",
            "        -5.2075, -7.9952, -5.3167, -8.6974, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1772, -2.6355, -3.8924, -5.5965, -5.0605, -4.5496, -3.3284, -5.1028,\n",
            "        -5.3090, -4.2025, -3.9994, -8.1505, -6.2400, -4.4380, -5.0915, -3.9346,\n",
            "        -3.8388, -5.6134, -8.3209, -4.1695, -4.0370, -3.7111, -4.8660, -6.0504,\n",
            "        -5.2063, -7.9933, -5.3160, -8.6960, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1752, -2.6407, -3.8923, -5.5953, -5.0591, -4.5497, -3.3274, -5.1031,\n",
            "        -5.3095, -4.1984, -3.9970, -8.1492, -6.2397, -4.4379, -5.0904, -3.9366,\n",
            "        -3.8387, -5.6115, -8.3194, -4.1692, -4.0367, -3.7085, -4.8645, -6.0496,\n",
            "        -5.2041, -7.9902, -5.3153, -8.6938, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1755, -2.6394, -3.8921, -5.5953, -5.0594, -4.5495, -3.3277, -5.1029,\n",
            "        -5.3094, -4.1994, -3.9976, -8.1492, -6.2395, -4.4380, -5.0905, -3.9361,\n",
            "        -3.8384, -5.6116, -8.3196, -4.1692, -4.0365, -3.7091, -4.8645, -6.0499,\n",
            "        -5.2047, -7.9905, -5.3155, -8.6940, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1750, -2.6394, -3.8919, -5.5950, -5.0589, -4.5496, -3.3276, -5.1028,\n",
            "        -5.3092, -4.1990, -3.9974, -8.1489, -6.2392, -4.4378, -5.0904, -3.9359,\n",
            "        -3.8383, -5.6114, -8.3190, -4.1690, -4.0362, -3.7089, -4.8642, -6.0495,\n",
            "        -5.2043, -7.9900, -5.3152, -8.6936, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1740, -2.6398, -3.8918, -5.5944, -5.0583, -4.5493, -3.3275, -5.1025,\n",
            "        -5.3087, -4.1985, -3.9970, -8.1479, -6.2386, -4.4374, -5.0900, -3.9358,\n",
            "        -3.8381, -5.6109, -8.3181, -4.1688, -4.0361, -3.7085, -4.8638, -6.0490,\n",
            "        -5.2035, -7.9890, -5.3145, -8.6928, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1737, -2.6395, -3.8915, -5.5942, -5.0580, -4.5492, -3.3274, -5.1023,\n",
            "        -5.3083, -4.1984, -3.9970, -8.1473, -6.2382, -4.4373, -5.0900, -3.9357,\n",
            "        -3.8379, -5.6106, -8.3176, -4.1684, -4.0362, -3.7082, -4.8635, -6.0487,\n",
            "        -5.2031, -7.9885, -5.3140, -8.6923, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1731, -2.6401, -3.8913, -5.5936, -5.0573, -4.5488, -3.3270, -5.1020,\n",
            "        -5.3080, -4.1974, -3.9964, -8.1463, -6.2377, -4.4370, -5.0893, -3.9357,\n",
            "        -3.8377, -5.6100, -8.3167, -4.1679, -4.0360, -3.7074, -4.8627, -6.0480,\n",
            "        -5.2019, -7.9874, -5.3135, -8.6915, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1729, -2.6411, -3.8910, -5.5934, -5.0570, -4.5490, -3.3265, -5.1024,\n",
            "        -5.3081, -4.1965, -3.9959, -8.1466, -6.2377, -4.4370, -5.0892, -3.9357,\n",
            "        -3.8376, -5.6099, -8.3168, -4.1679, -4.0360, -3.7068, -4.8624, -6.0481,\n",
            "        -5.2012, -7.9874, -5.3134, -8.6914, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1727, -2.6424, -3.8911, -5.5936, -5.0568, -4.5493, -3.3263, -5.1028,\n",
            "        -5.3084, -4.1954, -3.9954, -8.1467, -6.2379, -4.4370, -5.0892, -3.9361,\n",
            "        -3.8377, -5.6099, -8.3167, -4.1683, -4.0361, -3.7063, -4.8623, -6.0481,\n",
            "        -5.2009, -7.9872, -5.3137, -8.6913, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1718, -2.6458, -3.8914, -5.5934, -5.0558, -4.5497, -3.3257, -5.1038,\n",
            "        -5.3094, -4.1926, -3.9939, -8.1466, -6.2385, -4.4372, -5.0889, -3.9373,\n",
            "        -3.8381, -5.6092, -8.3161, -4.1683, -4.0361, -3.7047, -4.8620, -6.0479,\n",
            "        -5.1998, -7.9861, -5.3135, -8.6905, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1726, -2.6443, -3.8916, -5.5940, -5.0565, -4.5498, -3.3260, -5.1036,\n",
            "        -5.3093, -4.1941, -3.9947, -8.1472, -6.2385, -4.4375, -5.0894, -3.9370,\n",
            "        -3.8382, -5.6096, -8.3168, -4.1685, -4.0360, -3.7057, -4.8626, -6.0483,\n",
            "        -5.2009, -7.9870, -5.3137, -8.6911, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1739, -2.6405, -3.8915, -5.5947, -5.0576, -4.5494, -3.3267, -5.1027,\n",
            "        -5.3087, -4.1972, -3.9967, -8.1475, -6.2385, -4.4375, -5.0898, -3.9359,\n",
            "        -3.8380, -5.6102, -8.3177, -4.1684, -4.0360, -3.7079, -4.8634, -6.0489,\n",
            "        -5.2026, -7.9886, -5.3140, -8.6921, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1755, -2.6351, -3.8914, -5.5956, -5.0591, -4.5489, -3.3276, -5.1019,\n",
            "        -5.3080, -4.2014, -3.9992, -8.1483, -6.2384, -4.4377, -5.0904, -3.9344,\n",
            "        -3.8378, -5.6116, -8.3192, -4.1684, -4.0362, -3.7103, -4.8645, -6.0496,\n",
            "        -5.2047, -7.9909, -5.3145, -8.6936, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1764, -2.6325, -3.8914, -5.5959, -5.0599, -4.5487, -3.3281, -5.1013,\n",
            "        -5.3076, -4.2035, -4.0002, -8.1486, -6.2382, -4.4376, -5.0908, -3.9335,\n",
            "        -3.8377, -5.6122, -8.3196, -4.1684, -4.0364, -3.7113, -4.8652, -6.0498,\n",
            "        -5.2059, -7.9919, -5.3147, -8.6944, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1770, -2.6315, -3.8915, -5.5960, -5.0604, -4.5487, -3.3284, -5.1012,\n",
            "        -5.3076, -4.2045, -4.0006, -8.1490, -6.2383, -4.4375, -5.0910, -3.9330,\n",
            "        -3.8378, -5.6127, -8.3198, -4.1686, -4.0365, -3.7119, -4.8657, -6.0500,\n",
            "        -5.2064, -7.9925, -5.3149, -8.6951, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1778, -2.6305, -3.8917, -5.5964, -5.0610, -4.5488, -3.3288, -5.1014,\n",
            "        -5.3077, -4.2058, -4.0013, -8.1497, -6.2386, -4.4377, -5.0913, -3.9325,\n",
            "        -3.8379, -5.6134, -8.3205, -4.1688, -4.0369, -3.7128, -4.8665, -6.0504,\n",
            "        -5.2072, -7.9938, -5.3154, -8.6961, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1775, -2.6316, -3.8917, -5.5964, -5.0613, -4.5490, -3.3290, -5.1017,\n",
            "        -5.3081, -4.2051, -4.0009, -8.1496, -6.2390, -4.4377, -5.0913, -3.9329,\n",
            "        -3.8380, -5.6133, -8.3201, -4.1688, -4.0371, -3.7124, -4.8666, -6.0501,\n",
            "        -5.2071, -7.9935, -5.3156, -8.6962, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1774, -2.6319, -3.8918, -5.5963, -5.0614, -4.5490, -3.3291, -5.1019,\n",
            "        -5.3082, -4.2049, -4.0007, -8.1495, -6.2392, -4.4377, -5.0914, -3.9329,\n",
            "        -3.8380, -5.6133, -8.3201, -4.1690, -4.0370, -3.7124, -4.8667, -6.0501,\n",
            "        -5.2073, -7.9935, -5.3157, -8.6962, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1776, -2.6322, -3.8917, -5.5962, -5.0616, -4.5491, -3.3292, -5.1023,\n",
            "        -5.3085, -4.2047, -4.0004, -8.1498, -6.2394, -4.4377, -5.0916, -3.9331,\n",
            "        -3.8380, -5.6136, -8.3202, -4.1692, -4.0370, -3.7125, -4.8668, -6.0502,\n",
            "        -5.2074, -7.9940, -5.3161, -8.6966, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1775, -2.6330, -3.8917, -5.5962, -5.0613, -4.5491, -3.3292, -5.1025,\n",
            "        -5.3086, -4.2039, -3.9999, -8.1498, -6.2395, -4.4377, -5.0916, -3.9334,\n",
            "        -3.8381, -5.6134, -8.3200, -4.1692, -4.0370, -3.7121, -4.8667, -6.0500,\n",
            "        -5.2071, -7.9937, -5.3162, -8.6966, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1779, -2.6337, -3.8918, -5.5963, -5.0613, -4.5495, -3.3291, -5.1028,\n",
            "        -5.3090, -4.2034, -3.9996, -8.1502, -6.2398, -4.4379, -5.0917, -3.9336,\n",
            "        -3.8384, -5.6135, -8.3205, -4.1694, -4.0371, -3.7120, -4.8666, -6.0502,\n",
            "        -5.2070, -7.9938, -5.3164, -8.6971, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1786, -2.6322, -3.8919, -5.5968, -5.0617, -4.5495, -3.3293, -5.1030,\n",
            "        -5.3090, -4.2044, -4.0003, -8.1507, -6.2400, -4.4379, -5.0921, -3.9331,\n",
            "        -3.8385, -5.6142, -8.3211, -4.1697, -4.0373, -3.7127, -4.8672, -6.0506,\n",
            "        -5.2076, -7.9948, -5.3166, -8.6979, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1789, -2.6319, -3.8922, -5.5970, -5.0619, -4.5495, -3.3294, -5.1032,\n",
            "        -5.3091, -4.2045, -4.0006, -8.1511, -6.2404, -4.4378, -5.0922, -3.9331,\n",
            "        -3.8386, -5.6148, -8.3215, -4.1699, -4.0377, -3.7130, -4.8676, -6.0509,\n",
            "        -5.2081, -7.9953, -5.3169, -8.6984, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1791, -2.6321, -3.8924, -5.5970, -5.0624, -4.5497, -3.3297, -5.1034,\n",
            "        -5.3094, -4.2047, -4.0007, -8.1516, -6.2410, -4.4380, -5.0923, -3.9330,\n",
            "        -3.8388, -5.6151, -8.3220, -4.1700, -4.0379, -3.7131, -4.8678, -6.0512,\n",
            "        -5.2082, -7.9958, -5.3172, -8.6989, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1790, -2.6324, -3.8924, -5.5970, -5.0624, -4.5498, -3.3297, -5.1034,\n",
            "        -5.3094, -4.2046, -4.0006, -8.1518, -6.2411, -4.4382, -5.0923, -3.9331,\n",
            "        -3.8388, -5.6152, -8.3220, -4.1701, -4.0380, -3.7131, -4.8677, -6.0511,\n",
            "        -5.2081, -7.9958, -5.3171, -8.6986, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1791, -2.6332, -3.8926, -5.5970, -5.0624, -4.5502, -3.3297, -5.1039,\n",
            "        -5.3098, -4.2041, -4.0003, -8.1523, -6.2413, -4.4383, -5.0923, -3.9332,\n",
            "        -3.8390, -5.6153, -8.3223, -4.1701, -4.0380, -3.7130, -4.8679, -6.0513,\n",
            "        -5.2079, -7.9960, -5.3174, -8.6987, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1785, -2.6351, -3.8925, -5.5968, -5.0620, -4.5503, -3.3294, -5.1042,\n",
            "        -5.3102, -4.2027, -3.9994, -8.1519, -6.2414, -4.4383, -5.0921, -3.9337,\n",
            "        -3.8391, -5.6148, -8.3218, -4.1701, -4.0379, -3.7120, -4.8677, -6.0509,\n",
            "        -5.2073, -7.9952, -5.3172, -8.6980, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1778, -2.6369, -3.8926, -5.5965, -5.0614, -4.5504, -3.3290, -5.1041,\n",
            "        -5.3103, -4.2015, -3.9986, -8.1514, -6.2413, -4.4383, -5.0917, -3.9343,\n",
            "        -3.8391, -5.6141, -8.3213, -4.1701, -4.0378, -3.7112, -4.8671, -6.0505,\n",
            "        -5.2065, -7.9941, -5.3169, -8.6972, -0.4112], device='cuda:0') 28\n",
            "tensor([-7.1774, -2.6378, -3.8925, -5.5962, -5.0611, -4.5504, -3.3288, -5.1042,\n",
            "        -5.3105, -4.2007, -3.9982, -8.1509, -6.2412, -4.4383, -5.0915, -3.9345,\n",
            "        -3.8390, -5.6137, -8.3210, -4.1700, -4.0376, -3.7105, -4.8667, -6.0503,\n",
            "        -5.2060, -7.9935, -5.3165, -8.6967, -0.4112], device='cuda:0') 28\n",
            "tensor([-7.1772, -2.6368, -3.8924, -5.5962, -5.0609, -4.5503, -3.3287, -5.1039,\n",
            "        -5.3101, -4.2013, -3.9985, -8.1506, -6.2408, -4.4383, -5.0913, -3.9342,\n",
            "        -3.8388, -5.6134, -8.3207, -4.1699, -4.0374, -3.7107, -4.8666, -6.0503,\n",
            "        -5.2059, -7.9935, -5.3161, -8.6965, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1772, -2.6349, -3.8920, -5.5962, -5.0609, -4.5498, -3.3288, -5.1031,\n",
            "        -5.3094, -4.2026, -3.9992, -8.1500, -6.2402, -4.4381, -5.0913, -3.9337,\n",
            "        -3.8384, -5.6134, -8.3205, -4.1695, -4.0374, -3.7113, -4.8666, -6.0501,\n",
            "        -5.2062, -7.9936, -5.3157, -8.6965, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1772, -2.6339, -3.8918, -5.5962, -5.0609, -4.5495, -3.3291, -5.1027,\n",
            "        -5.3089, -4.2033, -3.9994, -8.1501, -6.2399, -4.4378, -5.0913, -3.9337,\n",
            "        -3.8384, -5.6133, -8.3203, -4.1692, -4.0373, -3.7118, -4.8665, -6.0501,\n",
            "        -5.2062, -7.9938, -5.3158, -8.6965, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1758, -2.6374, -3.8916, -5.5953, -5.0599, -4.5497, -3.3284, -5.1034,\n",
            "        -5.3094, -4.2005, -3.9976, -8.1493, -6.2399, -4.4377, -5.0910, -3.9348,\n",
            "        -3.8384, -5.6123, -8.3187, -4.1692, -4.0374, -3.7098, -4.8657, -6.0494,\n",
            "        -5.2048, -7.9918, -5.3154, -8.6951, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1756, -2.6375, -3.8916, -5.5950, -5.0599, -4.5497, -3.3283, -5.1033,\n",
            "        -5.3094, -4.2002, -3.9976, -8.1486, -6.2396, -4.4377, -5.0908, -3.9347,\n",
            "        -3.8384, -5.6120, -8.3185, -4.1691, -4.0372, -3.7096, -4.8655, -6.0493,\n",
            "        -5.2046, -7.9912, -5.3154, -8.6947, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1765, -2.6357, -3.8917, -5.5958, -5.0602, -4.5496, -3.3285, -5.1031,\n",
            "        -5.3092, -4.2017, -3.9986, -8.1492, -6.2395, -4.4378, -5.0911, -3.9344,\n",
            "        -3.8384, -5.6125, -8.3191, -4.1691, -4.0373, -3.7105, -4.8658, -6.0495,\n",
            "        -5.2056, -7.9923, -5.3156, -8.6956, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1772, -2.6335, -3.8918, -5.5962, -5.0609, -4.5493, -3.3287, -5.1027,\n",
            "        -5.3088, -4.2034, -3.9997, -8.1498, -6.2394, -4.4377, -5.0914, -3.9336,\n",
            "        -3.8383, -5.6132, -8.3202, -4.1690, -4.0374, -3.7116, -4.8666, -6.0499,\n",
            "        -5.2064, -7.9936, -5.3158, -8.6964, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1780, -2.6311, -3.8917, -5.5966, -5.0613, -4.5491, -3.3289, -5.1022,\n",
            "        -5.3083, -4.2052, -4.0007, -8.1501, -6.2392, -4.4377, -5.0918, -3.9327,\n",
            "        -3.8382, -5.6139, -8.3209, -4.1691, -4.0374, -3.7127, -4.8669, -6.0502,\n",
            "        -5.2073, -7.9946, -5.3158, -8.6970, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1788, -2.6284, -3.8917, -5.5970, -5.0622, -4.5488, -3.3293, -5.1018,\n",
            "        -5.3078, -4.2071, -4.0020, -8.1505, -6.2391, -4.4377, -5.0922, -3.9318,\n",
            "        -3.8380, -5.6148, -8.3219, -4.1691, -4.0373, -3.7139, -4.8674, -6.0510,\n",
            "        -5.2084, -7.9957, -5.3162, -8.6979, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1796, -2.6272, -3.8916, -5.5975, -5.0626, -4.5490, -3.3296, -5.1022,\n",
            "        -5.3079, -4.2080, -4.0025, -8.1515, -6.2394, -4.4377, -5.0925, -3.9313,\n",
            "        -3.8379, -5.6155, -8.3228, -4.1692, -4.0374, -3.7146, -4.8677, -6.0515,\n",
            "        -5.2088, -7.9967, -5.3164, -8.6988, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1790, -2.6285, -3.8917, -5.5974, -5.0623, -4.5491, -3.3294, -5.1022,\n",
            "        -5.3080, -4.2071, -4.0020, -8.1510, -6.2395, -4.4378, -5.0924, -3.9319,\n",
            "        -3.8381, -5.6152, -8.3221, -4.1693, -4.0373, -3.7141, -4.8673, -6.0511,\n",
            "        -5.2085, -7.9959, -5.3164, -8.6982, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1787, -2.6293, -3.8918, -5.5976, -5.0618, -4.5491, -3.3293, -5.1020,\n",
            "        -5.3079, -4.2067, -4.0018, -8.1507, -6.2396, -4.4378, -5.0921, -3.9323,\n",
            "        -3.8381, -5.6150, -8.3217, -4.1692, -4.0372, -3.7139, -4.8671, -6.0509,\n",
            "        -5.2081, -7.9953, -5.3161, -8.6977, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1789, -2.6291, -3.8918, -5.5976, -5.0620, -4.5491, -3.3294, -5.1020,\n",
            "        -5.3079, -4.2067, -4.0020, -8.1508, -6.2398, -4.4379, -5.0922, -3.9322,\n",
            "        -3.8382, -5.6152, -8.3218, -4.1695, -4.0371, -3.7142, -4.8673, -6.0511,\n",
            "        -5.2083, -7.9954, -5.3162, -8.6978, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1793, -2.6288, -3.8919, -5.5976, -5.0624, -4.5493, -3.3296, -5.1023,\n",
            "        -5.3082, -4.2068, -4.0018, -8.1513, -6.2399, -4.4378, -5.0924, -3.9321,\n",
            "        -3.8382, -5.6154, -8.3221, -4.1698, -4.0371, -3.7145, -4.8676, -6.0514,\n",
            "        -5.2085, -7.9960, -5.3164, -8.6983, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1791, -2.6292, -3.8918, -5.5975, -5.0620, -4.5494, -3.3295, -5.1023,\n",
            "        -5.3082, -4.2065, -4.0015, -8.1511, -6.2398, -4.4379, -5.0923, -3.9321,\n",
            "        -3.8383, -5.6153, -8.3220, -4.1699, -4.0370, -3.7144, -4.8673, -6.0513,\n",
            "        -5.2083, -7.9958, -5.3164, -8.6980, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1783, -2.6314, -3.8918, -5.5969, -5.0614, -4.5496, -3.3291, -5.1024,\n",
            "        -5.3085, -4.2052, -4.0006, -8.1504, -6.2396, -4.4379, -5.0920, -3.9331,\n",
            "        -3.8383, -5.6143, -8.3210, -4.1698, -4.0369, -3.7134, -4.8667, -6.0508,\n",
            "        -5.2076, -7.9946, -5.3163, -8.6969, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1781, -2.6322, -3.8920, -5.5966, -5.0614, -4.5497, -3.3290, -5.1025,\n",
            "        -5.3087, -4.2049, -4.0005, -8.1501, -6.2396, -4.4380, -5.0921, -3.9334,\n",
            "        -3.8385, -5.6138, -8.3209, -4.1697, -4.0369, -3.7130, -4.8668, -6.0508,\n",
            "        -5.2075, -7.9944, -5.3163, -8.6965, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1785, -2.6313, -3.8921, -5.5970, -5.0614, -4.5496, -3.3291, -5.1023,\n",
            "        -5.3085, -4.2056, -4.0010, -8.1504, -6.2395, -4.4379, -5.0922, -3.9332,\n",
            "        -3.8384, -5.6141, -8.3212, -4.1696, -4.0370, -3.7132, -4.8671, -6.0509,\n",
            "        -5.2079, -7.9947, -5.3163, -8.6969, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1788, -2.6292, -3.8918, -5.5971, -5.0619, -4.5493, -3.3293, -5.1018,\n",
            "        -5.3081, -4.2070, -4.0019, -8.1506, -6.2391, -4.4377, -5.0922, -3.9326,\n",
            "        -3.8382, -5.6144, -8.3216, -4.1691, -4.0371, -3.7139, -4.8673, -6.0509,\n",
            "        -5.2085, -7.9953, -5.3159, -8.6974, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1793, -2.6279, -3.8919, -5.5974, -5.0625, -4.5493, -3.3296, -5.1016,\n",
            "        -5.3078, -4.2078, -4.0025, -8.1510, -6.2391, -4.4378, -5.0923, -3.9319,\n",
            "        -3.8381, -5.6149, -8.3223, -4.1691, -4.0371, -3.7145, -4.8674, -6.0512,\n",
            "        -5.2089, -7.9961, -5.3161, -8.6979, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1788, -2.6283, -3.8916, -5.5971, -5.0622, -4.5490, -3.3294, -5.1013,\n",
            "        -5.3076, -4.2073, -4.0021, -8.1505, -6.2392, -4.4376, -5.0920, -3.9319,\n",
            "        -3.8379, -5.6148, -8.3218, -4.1689, -4.0370, -3.7142, -4.8671, -6.0508,\n",
            "        -5.2083, -7.9955, -5.3157, -8.6973, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1788, -2.6286, -3.8915, -5.5971, -5.0620, -4.5490, -3.3292, -5.1012,\n",
            "        -5.3077, -4.2069, -4.0020, -8.1505, -6.2391, -4.4376, -5.0918, -3.9321,\n",
            "        -3.8379, -5.6146, -8.3218, -4.1689, -4.0368, -3.7140, -4.8669, -6.0508,\n",
            "        -5.2081, -7.9954, -5.3157, -8.6970, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1787, -2.6287, -3.8915, -5.5971, -5.0617, -4.5490, -3.3292, -5.1011,\n",
            "        -5.3077, -4.2066, -4.0019, -8.1505, -6.2389, -4.4375, -5.0918, -3.9322,\n",
            "        -3.8380, -5.6145, -8.3215, -4.1689, -4.0366, -3.7140, -4.8667, -6.0507,\n",
            "        -5.2079, -7.9951, -5.3158, -8.6968, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1784, -2.6286, -3.8914, -5.5969, -5.0617, -4.5488, -3.3293, -5.1009,\n",
            "        -5.3075, -4.2070, -4.0020, -8.1501, -6.2386, -4.4375, -5.0918, -3.9320,\n",
            "        -3.8379, -5.6143, -8.3214, -4.1687, -4.0366, -3.7142, -4.8668, -6.0508,\n",
            "        -5.2078, -7.9950, -5.3159, -8.6965, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1783, -2.6286, -3.8913, -5.5967, -5.0618, -4.5487, -3.3293, -5.1008,\n",
            "        -5.3073, -4.2071, -4.0020, -8.1494, -6.2383, -4.4373, -5.0918, -3.9319,\n",
            "        -3.8378, -5.6140, -8.3208, -4.1686, -4.0368, -3.7140, -4.8669, -6.0505,\n",
            "        -5.2078, -7.9945, -5.3159, -8.6964, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1787, -2.6276, -3.8914, -5.5968, -5.0621, -4.5486, -3.3294, -5.1008,\n",
            "        -5.3071, -4.2079, -4.0024, -8.1495, -6.2383, -4.4372, -5.0918, -3.9315,\n",
            "        -3.8377, -5.6143, -8.3211, -4.1685, -4.0370, -3.7146, -4.8673, -6.0507,\n",
            "        -5.2082, -7.9951, -5.3160, -8.6967, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1798, -2.6259, -3.8916, -5.5974, -5.0630, -4.5488, -3.3298, -5.1011,\n",
            "        -5.3074, -4.2090, -4.0031, -8.1505, -6.2387, -4.4373, -5.0923, -3.9311,\n",
            "        -3.8378, -5.6152, -8.3223, -4.1688, -4.0372, -3.7155, -4.8680, -6.0515,\n",
            "        -5.2091, -7.9968, -5.3166, -8.6980, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1803, -2.6259, -3.8915, -5.5975, -5.0630, -4.5491, -3.3299, -5.1014,\n",
            "        -5.3076, -4.2092, -4.0031, -8.1510, -6.2390, -4.4374, -5.0926, -3.9310,\n",
            "        -3.8378, -5.6152, -8.3228, -4.1690, -4.0372, -3.7156, -4.8681, -6.0519,\n",
            "        -5.2091, -7.9973, -5.3168, -8.6984, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1801, -2.6265, -3.8917, -5.5975, -5.0629, -4.5492, -3.3299, -5.1016,\n",
            "        -5.3078, -4.2088, -4.0029, -8.1510, -6.2393, -4.4375, -5.0925, -3.9313,\n",
            "        -3.8380, -5.6152, -8.3228, -4.1691, -4.0373, -3.7153, -4.8681, -6.0517,\n",
            "        -5.2092, -7.9972, -5.3169, -8.6985, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1802, -2.6273, -3.8917, -5.5977, -5.0628, -4.5495, -3.3298, -5.1020,\n",
            "        -5.3082, -4.2084, -4.0026, -8.1514, -6.2396, -4.4378, -5.0925, -3.9317,\n",
            "        -3.8381, -5.6153, -8.3229, -4.1692, -4.0374, -3.7150, -4.8680, -6.0517,\n",
            "        -5.2093, -7.9972, -5.3171, -8.6986, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1798, -2.6280, -3.8917, -5.5975, -5.0627, -4.5494, -3.3297, -5.1020,\n",
            "        -5.3081, -4.2079, -4.0023, -8.1514, -6.2395, -4.4379, -5.0924, -3.9318,\n",
            "        -3.8381, -5.6151, -8.3227, -4.1691, -4.0373, -3.7146, -4.8676, -6.0516,\n",
            "        -5.2089, -7.9968, -5.3169, -8.6982, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1791, -2.6295, -3.8918, -5.5973, -5.0618, -4.5494, -3.3294, -5.1021,\n",
            "        -5.3080, -4.2065, -4.0017, -8.1511, -6.2394, -4.4379, -5.0918, -3.9322,\n",
            "        -3.8382, -5.6144, -8.3222, -4.1689, -4.0370, -3.7136, -4.8670, -6.0511,\n",
            "        -5.2080, -7.9958, -5.3164, -8.6976, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1789, -2.6297, -3.8919, -5.5972, -5.0617, -4.5494, -3.3292, -5.1020,\n",
            "        -5.3079, -4.2062, -4.0015, -8.1510, -6.2392, -4.4379, -5.0918, -3.9324,\n",
            "        -3.8382, -5.6144, -8.3220, -4.1688, -4.0371, -3.7134, -4.8668, -6.0508,\n",
            "        -5.2079, -7.9955, -5.3161, -8.6974, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1778, -2.6313, -3.8917, -5.5965, -5.0610, -4.5493, -3.3288, -5.1017,\n",
            "        -5.3078, -4.2049, -4.0009, -8.1500, -6.2388, -4.4378, -5.0915, -3.9329,\n",
            "        -3.8381, -5.6135, -8.3211, -4.1689, -4.0368, -3.7124, -4.8661, -6.0504,\n",
            "        -5.2071, -7.9942, -5.3156, -8.6963, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1771, -2.6319, -3.8916, -5.5962, -5.0605, -4.5491, -3.3287, -5.1014,\n",
            "        -5.3074, -4.2046, -4.0006, -8.1493, -6.2386, -4.4376, -5.0910, -3.9331,\n",
            "        -3.8380, -5.6130, -8.3204, -4.1686, -4.0367, -3.7122, -4.8658, -6.0498,\n",
            "        -5.2065, -7.9933, -5.3152, -8.6954, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1768, -2.6318, -3.8914, -5.5958, -5.0602, -4.5486, -3.3285, -5.1012,\n",
            "        -5.3072, -4.2045, -4.0005, -8.1487, -6.2384, -4.4373, -5.0907, -3.9329,\n",
            "        -3.8379, -5.6129, -8.3199, -4.1683, -4.0366, -3.7120, -4.8657, -6.0496,\n",
            "        -5.2063, -7.9927, -5.3148, -8.6950, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1771, -2.6304, -3.8912, -5.5958, -5.0607, -4.5485, -3.3287, -5.1009,\n",
            "        -5.3071, -4.2056, -4.0012, -8.1485, -6.2382, -4.4373, -5.0910, -3.9323,\n",
            "        -3.8377, -5.6131, -8.3200, -4.1683, -4.0366, -3.7128, -4.8661, -6.0498,\n",
            "        -5.2069, -7.9932, -5.3150, -8.6952, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1776, -2.6293, -3.8912, -5.5961, -5.0611, -4.5485, -3.3289, -5.1010,\n",
            "        -5.3072, -4.2064, -4.0018, -8.1489, -6.2383, -4.4374, -5.0913, -3.9320,\n",
            "        -3.8377, -5.6133, -8.3202, -4.1684, -4.0367, -3.7132, -4.8664, -6.0501,\n",
            "        -5.2075, -7.9938, -5.3153, -8.6957, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1782, -2.6280, -3.8912, -5.5966, -5.0614, -4.5485, -3.3291, -5.1010,\n",
            "        -5.3071, -4.2074, -4.0023, -8.1493, -6.2382, -4.4374, -5.0916, -3.9316,\n",
            "        -3.8377, -5.6139, -8.3207, -4.1685, -4.0369, -3.7138, -4.8668, -6.0504,\n",
            "        -5.2079, -7.9946, -5.3154, -8.6963, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1783, -2.6274, -3.8911, -5.5969, -5.0616, -4.5484, -3.3291, -5.1007,\n",
            "        -5.3069, -4.2079, -4.0026, -8.1492, -6.2381, -4.4374, -5.0918, -3.9316,\n",
            "        -3.8377, -5.6140, -8.3209, -4.1684, -4.0370, -3.7143, -4.8669, -6.0505,\n",
            "        -5.2083, -7.9948, -5.3156, -8.6965, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1791, -2.6259, -3.8913, -5.5971, -5.0623, -4.5483, -3.3294, -5.1007,\n",
            "        -5.3070, -4.2089, -4.0031, -8.1498, -6.2383, -4.4374, -5.0922, -3.9312,\n",
            "        -3.8377, -5.6146, -8.3216, -4.1686, -4.0370, -3.7152, -4.8676, -6.0512,\n",
            "        -5.2090, -7.9960, -5.3159, -8.6974, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1797, -2.6258, -3.8913, -5.5972, -5.0624, -4.5485, -3.3295, -5.1011,\n",
            "        -5.3073, -4.2090, -4.0031, -8.1506, -6.2386, -4.4375, -5.0924, -3.9310,\n",
            "        -3.8377, -5.6147, -8.3223, -4.1688, -4.0372, -3.7152, -4.8678, -6.0516,\n",
            "        -5.2090, -7.9967, -5.3161, -8.6980, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1797, -2.6256, -3.8913, -5.5972, -5.0627, -4.5485, -3.3296, -5.1012,\n",
            "        -5.3074, -4.2091, -4.0032, -8.1507, -6.2387, -4.4374, -5.0924, -3.9310,\n",
            "        -3.8377, -5.6150, -8.3224, -4.1688, -4.0372, -3.7153, -4.8679, -6.0517,\n",
            "        -5.2091, -7.9969, -5.3163, -8.6981, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1796, -2.6259, -3.8911, -5.5972, -5.0626, -4.5484, -3.3296, -5.1011,\n",
            "        -5.3073, -4.2091, -4.0030, -8.1505, -6.2387, -4.4375, -5.0922, -3.9310,\n",
            "        -3.8375, -5.6149, -8.3223, -4.1687, -4.0372, -3.7151, -4.8679, -6.0514,\n",
            "        -5.2089, -7.9968, -5.3162, -8.6979, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1796, -2.6262, -3.8912, -5.5972, -5.0625, -4.5485, -3.3296, -5.1011,\n",
            "        -5.3073, -4.2089, -4.0029, -8.1507, -6.2388, -4.4376, -5.0922, -3.9312,\n",
            "        -3.8375, -5.6148, -8.3222, -4.1688, -4.0371, -3.7149, -4.8676, -6.0513,\n",
            "        -5.2089, -7.9967, -5.3163, -8.6979, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1791, -2.6274, -3.8912, -5.5970, -5.0620, -4.5486, -3.3293, -5.1010,\n",
            "        -5.3073, -4.2080, -4.0025, -8.1503, -6.2387, -4.4375, -5.0918, -3.9315,\n",
            "        -3.8375, -5.6143, -8.3217, -4.1686, -4.0370, -3.7143, -4.8672, -6.0511,\n",
            "        -5.2083, -7.9959, -5.3160, -8.6973, -0.4122], device='cuda:0') 28\n",
            "tensor([-7.1785, -2.6285, -3.8911, -5.5967, -5.0616, -4.5486, -3.3291, -5.1010,\n",
            "        -5.3071, -4.2073, -4.0021, -8.1500, -6.2386, -4.4375, -5.0915, -3.9318,\n",
            "        -3.8375, -5.6139, -8.3213, -4.1685, -4.0369, -3.7137, -4.8668, -6.0507,\n",
            "        -5.2078, -7.9952, -5.3159, -8.6967, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1781, -2.6292, -3.8913, -5.5965, -5.0614, -4.5487, -3.3292, -5.1011,\n",
            "        -5.3071, -4.2070, -4.0018, -8.1496, -6.2385, -4.4375, -5.0916, -3.9320,\n",
            "        -3.8377, -5.6139, -8.3208, -4.1686, -4.0370, -3.7133, -4.8667, -6.0502,\n",
            "        -5.2077, -7.9946, -5.3159, -8.6964, -0.4121], device='cuda:0') 28\n",
            "tensor([-7.1773, -2.6310, -3.8914, -5.5963, -5.0608, -4.5489, -3.3290, -5.1013,\n",
            "        -5.3073, -4.2059, -4.0010, -8.1491, -6.2385, -4.4375, -5.0913, -3.9326,\n",
            "        -3.8380, -5.6134, -8.3198, -4.1688, -4.0371, -3.7127, -4.8664, -6.0495,\n",
            "        -5.2072, -7.9935, -5.3158, -8.6957, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1767, -2.6325, -3.8915, -5.5960, -5.0601, -4.5490, -3.3290, -5.1015,\n",
            "        -5.3075, -4.2047, -4.0002, -8.1487, -6.2386, -4.4374, -5.0911, -3.9330,\n",
            "        -3.8381, -5.6131, -8.3190, -4.1687, -4.0370, -3.7122, -4.8661, -6.0491,\n",
            "        -5.2066, -7.9926, -5.3154, -8.6951, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1753, -2.6370, -3.8916, -5.5952, -5.0591, -4.5494, -3.3286, -5.1023,\n",
            "        -5.3084, -4.2014, -3.9983, -8.1477, -6.2391, -4.4374, -5.0906, -3.9346,\n",
            "        -3.8383, -5.6118, -8.3173, -4.1687, -4.0370, -3.7102, -4.8654, -6.0485,\n",
            "        -5.2053, -7.9904, -5.3150, -8.6941, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1749, -2.6394, -3.8918, -5.5947, -5.0593, -4.5495, -3.3285, -5.1029,\n",
            "        -5.3094, -4.1994, -3.9972, -8.1474, -6.2397, -4.4375, -5.0906, -3.9355,\n",
            "        -3.8386, -5.6115, -8.3167, -4.1689, -4.0371, -3.7092, -4.8653, -6.0486,\n",
            "        -5.2049, -7.9896, -5.3153, -8.6941, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1743, -2.6433, -3.8922, -5.5944, -5.0590, -4.5503, -3.3281, -5.1042,\n",
            "        -5.3109, -4.1963, -3.9955, -8.1476, -6.2409, -4.4378, -5.0905, -3.9366,\n",
            "        -3.8390, -5.6114, -8.3162, -4.1695, -4.0372, -3.7078, -4.8651, -6.0485,\n",
            "        -5.2041, -7.9887, -5.3156, -8.6942, -0.4110], device='cuda:0') 28\n",
            "tensor([-7.1740, -2.6460, -3.8924, -5.5941, -5.0587, -4.5509, -3.3277, -5.1050,\n",
            "        -5.3120, -4.1943, -3.9943, -8.1478, -6.2416, -4.4380, -5.0902, -3.9374,\n",
            "        -3.8393, -5.6111, -8.3162, -4.1699, -4.0373, -3.7067, -4.8652, -6.0486,\n",
            "        -5.2033, -7.9882, -5.3158, -8.6939, -0.4108], device='cuda:0') 28\n",
            "tensor([-7.1744, -2.6478, -3.8931, -5.5944, -5.0590, -4.5515, -3.3276, -5.1058,\n",
            "        -5.3129, -4.1934, -3.9938, -8.1489, -6.2425, -4.4383, -5.0902, -3.9381,\n",
            "        -3.8397, -5.6114, -8.3170, -4.1702, -4.0375, -3.7063, -4.8655, -6.0489,\n",
            "        -5.2034, -7.9887, -5.3163, -8.6944, -0.4105], device='cuda:0') 28\n",
            "tensor([-7.1737, -2.6498, -3.8931, -5.5942, -5.0583, -4.5514, -3.3271, -5.1057,\n",
            "        -5.3128, -4.1920, -3.9931, -8.1488, -6.2424, -4.4384, -5.0898, -3.9389,\n",
            "        -3.8396, -5.6106, -8.3167, -4.1701, -4.0373, -3.7053, -4.8646, -6.0486,\n",
            "        -5.2028, -7.9877, -5.3159, -8.6935, -0.4105], device='cuda:0') 28\n",
            "tensor([-7.1734, -2.6481, -3.8926, -5.5942, -5.0576, -4.5507, -3.3269, -5.1045,\n",
            "        -5.3113, -4.1931, -3.9938, -8.1482, -6.2410, -4.4382, -5.0895, -3.9386,\n",
            "        -3.8391, -5.6100, -8.3166, -4.1694, -4.0366, -3.7058, -4.8638, -6.0485,\n",
            "        -5.2026, -7.9874, -5.3152, -8.6925, -0.4107], device='cuda:0') 28\n",
            "tensor([-7.1738, -2.6440, -3.8920, -5.5945, -5.0577, -4.5500, -3.3271, -5.1035,\n",
            "        -5.3099, -4.1958, -3.9954, -8.1481, -6.2399, -4.4379, -5.0897, -3.9372,\n",
            "        -3.8385, -5.6103, -8.3172, -4.1689, -4.0364, -3.7071, -4.8637, -6.0487,\n",
            "        -5.2030, -7.9883, -5.3147, -8.6926, -0.4111], device='cuda:0') 28\n",
            "tensor([-7.1726, -2.6455, -3.8920, -5.5937, -5.0566, -4.5498, -3.3265, -5.1033,\n",
            "        -5.3096, -4.1942, -3.9946, -8.1468, -6.2392, -4.4376, -5.0893, -3.9378,\n",
            "        -3.8384, -5.6094, -8.3159, -4.1686, -4.0359, -3.7059, -4.8628, -6.0481,\n",
            "        -5.2017, -7.9866, -5.3141, -8.6911, -0.4112], device='cuda:0') 28\n",
            "tensor([-7.1708, -2.6480, -3.8916, -5.5926, -5.0552, -4.5494, -3.3256, -5.1029,\n",
            "        -5.3094, -4.1915, -3.9929, -8.1450, -6.2384, -4.4369, -5.0884, -3.9385,\n",
            "        -3.8382, -5.6081, -8.3141, -4.1680, -4.0357, -3.7041, -4.8613, -6.0470,\n",
            "        -5.1997, -7.9845, -5.3130, -8.6895, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1699, -2.6490, -3.8915, -5.5917, -5.0545, -4.5493, -3.3252, -5.1026,\n",
            "        -5.3092, -4.1903, -3.9922, -8.1443, -6.2379, -4.4366, -5.0878, -3.9386,\n",
            "        -3.8381, -5.6073, -8.3132, -4.1674, -4.0356, -3.7032, -4.8607, -6.0465,\n",
            "        -5.1986, -7.9833, -5.3124, -8.6884, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1690, -2.6516, -3.8916, -5.5913, -5.0537, -4.5496, -3.3248, -5.1031,\n",
            "        -5.3096, -4.1880, -3.9908, -8.1440, -6.2379, -4.4364, -5.0875, -3.9393,\n",
            "        -3.8382, -5.6070, -8.3125, -4.1674, -4.0354, -3.7016, -4.8600, -6.0461,\n",
            "        -5.1973, -7.9821, -5.3122, -8.6879, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1687, -2.6526, -3.8917, -5.5910, -5.0537, -4.5497, -3.3247, -5.1032,\n",
            "        -5.3095, -4.1874, -3.9904, -8.1439, -6.2379, -4.4364, -5.0872, -3.9391,\n",
            "        -3.8382, -5.6070, -8.3125, -4.1674, -4.0354, -3.7013, -4.8599, -6.0461,\n",
            "        -5.1967, -7.9818, -5.3121, -8.6877, -0.4112], device='cuda:0') 28\n",
            "tensor([-7.1682, -2.6554, -3.8918, -5.5909, -5.0534, -4.5502, -3.3244, -5.1039,\n",
            "        -5.3103, -4.1854, -3.9891, -8.1441, -6.2384, -4.4366, -5.0871, -3.9401,\n",
            "        -3.8383, -5.6066, -8.3122, -4.1676, -4.0357, -3.7001, -4.8598, -6.0460,\n",
            "        -5.1959, -7.9811, -5.3124, -8.6875, -0.4110], device='cuda:0') 28\n",
            "tensor([-7.1690, -2.6542, -3.8919, -5.5911, -5.0540, -4.5503, -3.3247, -5.1042,\n",
            "        -5.3104, -4.1864, -3.9899, -8.1446, -6.2388, -4.4368, -5.0874, -3.9396,\n",
            "        -3.8383, -5.6071, -8.3128, -4.1679, -4.0357, -3.7010, -4.8602, -6.0463,\n",
            "        -5.1966, -7.9819, -5.3129, -8.6881, -0.4110], device='cuda:0') 28\n",
            "tensor([-7.1683, -2.6582, -3.8922, -5.5908, -5.0536, -4.5510, -3.3244, -5.1054,\n",
            "        -5.3121, -4.1834, -3.9881, -8.1446, -6.2402, -4.4371, -5.0871, -3.9407,\n",
            "        -3.8389, -5.6068, -8.3123, -4.1686, -4.0361, -3.6994, -4.8602, -6.0460,\n",
            "        -5.1957, -7.9813, -5.3133, -8.6883, -0.4106], device='cuda:0') 28\n",
            "tensor([-7.1668, -2.6654, -3.8929, -5.5901, -5.0527, -4.5521, -3.3235, -5.1072,\n",
            "        -5.3144, -4.1778, -3.9849, -8.1441, -6.2417, -4.4374, -5.0864, -3.9427,\n",
            "        -3.8397, -5.6059, -8.3108, -4.1692, -4.0363, -3.6962, -4.8599, -6.0456,\n",
            "        -5.1937, -7.9791, -5.3135, -8.6874, -0.4101], device='cuda:0') 28\n",
            "tensor([-7.1662, -2.6696, -3.8938, -5.5899, -5.0529, -4.5528, -3.3235, -5.1084,\n",
            "        -5.3162, -4.1750, -3.9832, -8.1440, -6.2435, -4.4378, -5.0860, -3.9440,\n",
            "        -3.8406, -5.6057, -8.3099, -4.1700, -4.0367, -3.6947, -4.8603, -6.0455,\n",
            "        -5.1936, -7.9780, -5.3142, -8.6875, -0.4097], device='cuda:0') 28\n",
            "tensor([-7.1666, -2.6698, -3.8942, -5.5901, -5.0538, -4.5528, -3.3240, -5.1087,\n",
            "        -5.3167, -4.1755, -3.9834, -8.1443, -6.2443, -4.4382, -5.0863, -3.9442,\n",
            "        -3.8409, -5.6061, -8.3099, -4.1704, -4.0372, -3.6949, -4.8612, -6.0456,\n",
            "        -5.1947, -7.9781, -5.3148, -8.6883, -0.4095], device='cuda:0') 28\n",
            "tensor([-7.1687, -2.6662, -3.8944, -5.5913, -5.0554, -4.5532, -3.3249, -5.1086,\n",
            "        -5.3168, -4.1790, -3.9854, -8.1458, -6.2449, -4.4387, -5.0874, -3.9433,\n",
            "        -3.8409, -5.6074, -8.3117, -4.1709, -4.0375, -3.6973, -4.8627, -6.0466,\n",
            "        -5.1971, -7.9804, -5.3156, -8.6901, -0.4095], device='cuda:0') 28\n",
            "tensor([-7.1709, -2.6580, -3.8938, -5.5926, -5.0568, -4.5523, -3.3261, -5.1069,\n",
            "        -5.3146, -4.1857, -3.9894, -8.1462, -6.2433, -4.4385, -5.0886, -3.9411,\n",
            "        -3.8402, -5.6086, -8.3133, -4.1703, -4.0374, -3.7013, -4.8637, -6.0474,\n",
            "        -5.2001, -7.9834, -5.3156, -8.6914, -0.4100], device='cuda:0') 28\n",
            "tensor([-7.1741, -2.6466, -3.8930, -5.5942, -5.0589, -4.5509, -3.3278, -5.1047,\n",
            "        -5.3119, -4.1947, -3.9946, -8.1476, -6.2413, -4.4383, -5.0904, -3.9380,\n",
            "        -3.8393, -5.6106, -8.3161, -4.1695, -4.0371, -3.7067, -4.8651, -6.0487,\n",
            "        -5.2039, -7.9878, -5.3158, -8.6936, -0.4107], device='cuda:0') 28\n",
            "tensor([-7.1764, -2.6372, -3.8922, -5.5957, -5.0601, -4.5499, -3.3287, -5.1028,\n",
            "        -5.3094, -4.2017, -3.9987, -8.1485, -6.2398, -4.4379, -5.0915, -3.9352,\n",
            "        -3.8385, -5.6121, -8.3183, -4.1692, -4.0370, -3.7108, -4.8661, -6.0496,\n",
            "        -5.2066, -7.9911, -5.3159, -8.6952, -0.4113], device='cuda:0') 28\n",
            "tensor([-7.1775, -2.6322, -3.8918, -5.5963, -5.0611, -4.5492, -3.3291, -5.1018,\n",
            "        -5.3082, -4.2052, -4.0007, -8.1489, -6.2389, -4.4376, -5.0920, -3.9335,\n",
            "        -3.8381, -5.6130, -8.3196, -4.1689, -4.0370, -3.7128, -4.8668, -6.0502,\n",
            "        -5.2079, -7.9931, -5.3159, -8.6961, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1781, -2.6294, -3.8914, -5.5963, -5.0615, -4.5488, -3.3294, -5.1012,\n",
            "        -5.3075, -4.2069, -4.0016, -8.1493, -6.2388, -4.4374, -5.0921, -3.9324,\n",
            "        -3.8378, -5.6138, -8.3204, -4.1687, -4.0371, -3.7137, -4.8670, -6.0502,\n",
            "        -5.2084, -7.9944, -5.3158, -8.6968, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1781, -2.6290, -3.8912, -5.5963, -5.0615, -4.5488, -3.3294, -5.1010,\n",
            "        -5.3073, -4.2071, -4.0017, -8.1492, -6.2386, -4.4373, -5.0921, -3.9322,\n",
            "        -3.8377, -5.6139, -8.3203, -4.1686, -4.0370, -3.7138, -4.8668, -6.0500,\n",
            "        -5.2084, -7.9944, -5.3157, -8.6967, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1776, -2.6305, -3.8912, -5.5964, -5.0610, -4.5490, -3.3292, -5.1011,\n",
            "        -5.3074, -4.2061, -4.0012, -8.1490, -6.2386, -4.4374, -5.0917, -3.9328,\n",
            "        -3.8378, -5.6136, -8.3198, -4.1687, -4.0368, -3.7131, -4.8663, -6.0495,\n",
            "        -5.2078, -7.9936, -5.3157, -8.6961, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1767, -2.6335, -3.8915, -5.5960, -5.0603, -4.5492, -3.3289, -5.1011,\n",
            "        -5.3076, -4.2045, -4.0001, -8.1481, -6.2387, -4.4374, -5.0913, -3.9340,\n",
            "        -3.8382, -5.6126, -8.3184, -4.1688, -4.0368, -3.7121, -4.8659, -6.0488,\n",
            "        -5.2071, -7.9919, -5.3156, -8.6949, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1763, -2.6345, -3.8915, -5.5959, -5.0601, -4.5493, -3.3288, -5.1014,\n",
            "        -5.3077, -4.2038, -3.9998, -8.1480, -6.2388, -4.4375, -5.0912, -3.9343,\n",
            "        -3.8382, -5.6122, -8.3181, -4.1688, -4.0368, -3.7117, -4.8658, -6.0488,\n",
            "        -5.2068, -7.9916, -5.3156, -8.6946, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1766, -2.6338, -3.8916, -5.5960, -5.0604, -4.5492, -3.3289, -5.1016,\n",
            "        -5.3077, -4.2041, -3.9999, -8.1484, -6.2387, -4.4376, -5.0914, -3.9342,\n",
            "        -3.8381, -5.6124, -8.3186, -4.1688, -4.0368, -3.7119, -4.8660, -6.0492,\n",
            "        -5.2069, -7.9922, -5.3157, -8.6951, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1767, -2.6327, -3.8915, -5.5960, -5.0605, -4.5489, -3.3289, -5.1014,\n",
            "        -5.3074, -4.2046, -4.0002, -8.1484, -6.2385, -4.4375, -5.0915, -3.9338,\n",
            "        -3.8380, -5.6127, -8.3190, -4.1687, -4.0368, -3.7121, -4.8660, -6.0492,\n",
            "        -5.2070, -7.9923, -5.3155, -8.6953, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1763, -2.6332, -3.8914, -5.5958, -5.0602, -4.5487, -3.3288, -5.1013,\n",
            "        -5.3074, -4.2041, -4.0000, -8.1481, -6.2384, -4.4375, -5.0914, -3.9339,\n",
            "        -3.8379, -5.6124, -8.3188, -4.1686, -4.0366, -3.7118, -4.8657, -6.0492,\n",
            "        -5.2067, -7.9919, -5.3153, -8.6949, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1757, -2.6337, -3.8911, -5.5954, -5.0596, -4.5484, -3.3285, -5.1008,\n",
            "        -5.3072, -4.2038, -3.9997, -8.1471, -6.2380, -4.4373, -5.0908, -3.9341,\n",
            "        -3.8377, -5.6118, -8.3178, -4.1683, -4.0365, -3.7112, -4.8648, -6.0485,\n",
            "        -5.2061, -7.9910, -5.3149, -8.6941, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1753, -2.6343, -3.8912, -5.5952, -5.0590, -4.5483, -3.3282, -5.1006,\n",
            "        -5.3071, -4.2029, -3.9994, -8.1467, -6.2379, -4.4371, -5.0907, -3.9344,\n",
            "        -3.8377, -5.6116, -8.3173, -4.1682, -4.0361, -3.7108, -4.8645, -6.0483,\n",
            "        -5.2057, -7.9902, -5.3145, -8.6934, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1751, -2.6342, -3.8912, -5.5949, -5.0588, -4.5481, -3.3281, -5.1003,\n",
            "        -5.3067, -4.2030, -3.9994, -8.1465, -6.2376, -4.4371, -5.0906, -3.9344,\n",
            "        -3.8377, -5.6114, -8.3168, -4.1681, -4.0361, -3.7107, -4.8644, -6.0483,\n",
            "        -5.2056, -7.9898, -5.3142, -8.6931, -0.4120], device='cuda:0') 28\n",
            "tensor([-7.1747, -2.6349, -3.8913, -5.5947, -5.0586, -4.5482, -3.3281, -5.1003,\n",
            "        -5.3066, -4.2025, -3.9992, -8.1462, -6.2375, -4.4371, -5.0904, -3.9346,\n",
            "        -3.8377, -5.6112, -8.3163, -4.1681, -4.0361, -3.7105, -4.8642, -6.0481,\n",
            "        -5.2055, -7.9893, -5.3141, -8.6929, -0.4119], device='cuda:0') 28\n",
            "tensor([-7.1744, -2.6361, -3.8913, -5.5945, -5.0584, -4.5483, -3.3279, -5.1004,\n",
            "        -5.3068, -4.2017, -3.9987, -8.1460, -6.2377, -4.4371, -5.0902, -3.9350,\n",
            "        -3.8377, -5.6109, -8.3160, -4.1682, -4.0361, -3.7101, -4.8639, -6.0479,\n",
            "        -5.2050, -7.9886, -5.3141, -8.6924, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1742, -2.6385, -3.8915, -5.5944, -5.0580, -4.5490, -3.3276, -5.1008,\n",
            "        -5.3074, -4.2005, -3.9979, -8.1461, -6.2382, -4.4374, -5.0900, -3.9361,\n",
            "        -3.8380, -5.6105, -8.3159, -4.1686, -4.0362, -3.7096, -4.8640, -6.0480,\n",
            "        -5.2045, -7.9883, -5.3144, -8.6921, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1743, -2.6420, -3.8923, -5.5944, -5.0583, -4.5497, -3.3277, -5.1020,\n",
            "        -5.3088, -4.1986, -3.9969, -8.1467, -6.2396, -4.4377, -5.0900, -3.9372,\n",
            "        -3.8386, -5.6104, -8.3160, -4.1691, -4.0365, -3.7086, -4.8644, -6.0482,\n",
            "        -5.2045, -7.9880, -5.3151, -8.6922, -0.4111], device='cuda:0') 28\n",
            "tensor([-7.1744, -2.6445, -3.8927, -5.5947, -5.0585, -4.5502, -3.3276, -5.1029,\n",
            "        -5.3100, -4.1970, -3.9961, -8.1475, -6.2406, -4.4381, -5.0902, -3.9381,\n",
            "        -3.8389, -5.6104, -8.3162, -4.1695, -4.0366, -3.7076, -4.8646, -6.0485,\n",
            "        -5.2047, -7.9878, -5.3157, -8.6927, -0.4109], device='cuda:0') 28\n",
            "tensor([-7.1751, -2.6436, -3.8930, -5.5954, -5.0592, -4.5503, -3.3281, -5.1033,\n",
            "        -5.3101, -4.1977, -3.9967, -8.1486, -6.2410, -4.4385, -5.0908, -3.9380,\n",
            "        -3.8389, -5.6110, -8.3172, -4.1698, -4.0368, -3.7082, -4.8651, -6.0493,\n",
            "        -5.2055, -7.9888, -5.3163, -8.6940, -0.4108], device='cuda:0') 28\n",
            "tensor([-7.1752, -2.6413, -3.8925, -5.5952, -5.0591, -4.5499, -3.3280, -5.1027,\n",
            "        -5.3092, -4.1988, -3.9972, -8.1482, -6.2399, -4.4381, -5.0907, -3.9373,\n",
            "        -3.8386, -5.6109, -8.3169, -4.1693, -4.0367, -3.7087, -4.8648, -6.0490,\n",
            "        -5.2053, -7.9890, -5.3157, -8.6939, -0.4111], device='cuda:0') 28\n",
            "tensor([-7.1742, -2.6403, -3.8919, -5.5945, -5.0586, -4.5494, -3.3277, -5.1021,\n",
            "        -5.3084, -4.1988, -3.9971, -8.1469, -6.2390, -4.4376, -5.0904, -3.9368,\n",
            "        -3.8383, -5.6103, -8.3162, -4.1688, -4.0365, -3.7087, -4.8643, -6.0485,\n",
            "        -5.2046, -7.9884, -5.3147, -8.6930, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1738, -2.6390, -3.8915, -5.5940, -5.0584, -4.5488, -3.3277, -5.1017,\n",
            "        -5.3080, -4.1991, -3.9974, -8.1461, -6.2385, -4.4373, -5.0901, -3.9361,\n",
            "        -3.8379, -5.6104, -8.3159, -4.1683, -4.0364, -3.7087, -4.8639, -6.0483,\n",
            "        -5.2043, -7.9881, -5.3144, -8.6928, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1722, -2.6429, -3.8914, -5.5930, -5.0567, -4.5487, -3.3267, -5.1018,\n",
            "        -5.3084, -4.1958, -3.9953, -8.1452, -6.2384, -4.4371, -5.0893, -3.9371,\n",
            "        -3.8381, -5.6094, -8.3143, -4.1680, -4.0363, -3.7065, -4.8625, -6.0472,\n",
            "        -5.2021, -7.9859, -5.3135, -8.6910, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1704, -2.6463, -3.8912, -5.5921, -5.0554, -4.5486, -3.3258, -5.1017,\n",
            "        -5.3084, -4.1931, -3.9936, -8.1439, -6.2380, -4.4368, -5.0883, -3.9381,\n",
            "        -3.8382, -5.6079, -8.3126, -4.1677, -4.0363, -3.7046, -4.8616, -6.0463,\n",
            "        -5.2001, -7.9836, -5.3127, -8.6891, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1695, -2.6479, -3.8914, -5.5917, -5.0550, -4.5488, -3.3255, -5.1020,\n",
            "        -5.3084, -4.1914, -3.9927, -8.1435, -6.2378, -4.4368, -5.0880, -3.9385,\n",
            "        -3.8382, -5.6074, -8.3121, -4.1676, -4.0363, -3.7035, -4.8613, -6.0460,\n",
            "        -5.1992, -7.9827, -5.3124, -8.6885, -0.4114], device='cuda:0') 28\n",
            "tensor([-7.1698, -2.6461, -3.8913, -5.5920, -5.0554, -4.5488, -3.3258, -5.1017,\n",
            "        -5.3080, -4.1929, -3.9936, -8.1435, -6.2375, -4.4367, -5.0882, -3.9379,\n",
            "        -3.8380, -5.6076, -8.3122, -4.1676, -4.0361, -3.7044, -4.8616, -6.0463,\n",
            "        -5.1999, -7.9831, -5.3124, -8.6887, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1700, -2.6456, -3.8913, -5.5920, -5.0556, -4.5488, -3.3259, -5.1015,\n",
            "        -5.3080, -4.1933, -3.9940, -8.1435, -6.2374, -4.4367, -5.0884, -3.9378,\n",
            "        -3.8380, -5.6077, -8.3122, -4.1676, -4.0360, -3.7047, -4.8617, -6.0464,\n",
            "        -5.2001, -7.9832, -5.3125, -8.6887, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1710, -2.6437, -3.8913, -5.5926, -5.0561, -4.5489, -3.3264, -5.1014,\n",
            "        -5.3078, -4.1949, -3.9949, -8.1440, -6.2377, -4.4369, -5.0888, -3.9373,\n",
            "        -3.8380, -5.6083, -8.3128, -4.1677, -4.0360, -3.7059, -4.8622, -6.0467,\n",
            "        -5.2011, -7.9843, -5.3129, -8.6895, -0.4115], device='cuda:0') 28\n",
            "tensor([-7.1722, -2.6408, -3.8911, -5.5934, -5.0571, -4.5488, -3.3271, -5.1012,\n",
            "        -5.3075, -4.1976, -3.9963, -8.1448, -6.2378, -4.4371, -5.0894, -3.9363,\n",
            "        -3.8379, -5.6092, -8.3139, -4.1681, -4.0361, -3.7077, -4.8631, -6.0473,\n",
            "        -5.2025, -7.9862, -5.3135, -8.6905, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1733, -2.6392, -3.8912, -5.5939, -5.0580, -4.5489, -3.3275, -5.1014,\n",
            "        -5.3076, -4.1992, -3.9971, -8.1457, -6.2379, -4.4371, -5.0899, -3.9359,\n",
            "        -3.8380, -5.6098, -8.3151, -4.1683, -4.0363, -3.7087, -4.8641, -6.0478,\n",
            "        -5.2036, -7.9879, -5.3142, -8.6916, -0.4116], device='cuda:0') 28\n",
            "tensor([-7.1742, -2.6372, -3.8913, -5.5942, -5.0587, -4.5488, -3.3279, -5.1014,\n",
            "        -5.3074, -4.2007, -3.9979, -8.1463, -6.2380, -4.4371, -5.0903, -3.9352,\n",
            "        -3.8379, -5.6105, -8.3162, -4.1684, -4.0364, -3.7097, -4.8646, -6.0482,\n",
            "        -5.2046, -7.9893, -5.3144, -8.6928, -0.4117], device='cuda:0') 28\n",
            "tensor([-7.1750, -2.6350, -3.8912, -5.5945, -5.0592, -4.5485, -3.3284, -5.1010,\n",
            "        -5.3071, -4.2022, -3.9987, -8.1464, -6.2378, -4.4371, -5.0906, -3.9345,\n",
            "        -3.8377, -5.6111, -8.3169, -4.1683, -4.0363, -3.7107, -4.8649, -6.0485,\n",
            "        -5.2054, -7.9901, -5.3146, -8.6933, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1748, -2.6360, -3.8911, -5.5940, -5.0589, -4.5486, -3.3282, -5.1012,\n",
            "        -5.3074, -4.2014, -3.9983, -8.1462, -6.2378, -4.4371, -5.0904, -3.9347,\n",
            "        -3.8376, -5.6108, -8.3165, -4.1682, -4.0362, -3.7101, -4.8645, -6.0484,\n",
            "        -5.2049, -7.9895, -5.3146, -8.6928, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1745, -2.6369, -3.8911, -5.5938, -5.0586, -4.5489, -3.3281, -5.1013,\n",
            "        -5.3077, -4.2006, -3.9979, -8.1464, -6.2380, -4.4370, -5.0904, -3.9350,\n",
            "        -3.8377, -5.6107, -8.3162, -4.1682, -4.0361, -3.7095, -4.8641, -6.0480,\n",
            "        -5.2045, -7.9891, -5.3145, -8.6925, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1745, -2.6359, -3.8910, -5.5938, -5.0589, -4.5487, -3.3283, -5.1011,\n",
            "        -5.3076, -4.2015, -3.9984, -8.1462, -6.2377, -4.4370, -5.0905, -3.9345,\n",
            "        -3.8377, -5.6109, -8.3162, -4.1681, -4.0363, -3.7099, -4.8643, -6.0481,\n",
            "        -5.2048, -7.9893, -5.3144, -8.6926, -0.4118], device='cuda:0') 28\n",
            "tensor([-7.1740, -2.6365, -3.8910, -5.5937, -5.0586, -4.5484, -3.3281, -5.1008,\n",
            "        -5.3074, -4.2011, -3.9982, -8.1457, -6.2375, -4.4369, -5.0902, -3.9348,\n",
            "        -3.8376, -5.6104, -8.3156, -4.1679, -4.0363, -3.7095, -4.8641, -6.0478,\n",
            "        -5.2045, -7.9885, -5.3142, -8.6920, -0.4118], device='cuda:0') 28\n",
            "<class 'list'> 5 <class 'list'>\n",
            "# predicted text: kenneth and beth refrained from telling the other girls or uncle john of old will rogers's visit but they got mister watson in the library and questioned him closely about the penalty for forging a check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T57YOK2WjsPm"
      },
      "source": [
        "## Original Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZodve8PGKfS"
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set, experiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92kVVEr7GR6j"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucfQX3qN21az"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7J9Gf4QtvNs"
      },
      "source": [
        "# My learning code \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOlL3uB6t4ZS"
      },
      "source": [
        "if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "        \n",
        "test_url=\"test-clean\"\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cei39GivZFE",
        "outputId": "bce6746e-92c2-4a7a-9120-4567e97571a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(type(test_dataset))\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "print(use_cuda)\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=5, # originaly 20\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "print(type(test_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchaudio.datasets.librispeech.LIBRISPEECH'>\n",
            "True\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIe3KLAwzgZo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "local_audio_transforms = nn.Sequential(\n",
        "    # https://pytorch.org/audio/transforms.html#melspectrogram\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128)#,\n",
        "    # https://pytorch.org/audio/transforms.html#frequencymasking\n",
        "    #torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    # https://pytorch.org/audio/transforms.html#timemasking\n",
        "    #torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "spectrograms = []\n",
        "labels = []\n",
        "input_lengths = []\n",
        "label_lengths = []\n",
        "\n",
        "inx = 0\n",
        "for (waveform, sample_rate, utterance, B, C, D) in test_dataset:\n",
        "    inx += 1\n",
        "    print(type(sample_rate))\n",
        "    print(type(B))\n",
        "    print(type(C))\n",
        "    print(type(D))\n",
        "    print(type(waveform))\n",
        "    print(type(utterance))\n",
        "    print(utterance)\n",
        "    print(f\"sample_rate={sample_rate} B={B} C={C} D={D}\")\n",
        "    \n",
        "    print(type(waveform))\n",
        "    print(\"Shape of waveform: {}\".format(waveform.size()))\n",
        "    print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
        "\n",
        "    if inx == 10:\n",
        "        # define 2 sub plots\n",
        "        fig, axs = plt.subplots(2)\n",
        "        #fig.suptitle('Vertically stacked subplots')\n",
        "        #axs[0].plot(x, y)\n",
        "        #axs[1].plot(x, -y)\n",
        "\n",
        "        #plt.figure()\n",
        "        axs[0].plot(waveform.t().numpy())  \n",
        "\n",
        "        spec = local_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        print(\"type(spec) is \", type(spec)) \n",
        "        print(\"Shape of spec: {}\".format(spec.size()))\n",
        "        #    axs[1].imshow(spec.log2().detach().numpy(), cmap='gray')\n",
        "        axs[1].imshow(torch.transpose(spec, 0, 1).log2().numpy(), cmap='gray')\n",
        "\n",
        "\n",
        "    # the 4 elements of the test_loader are defined by  def data_processing(..)\n",
        "    #           return  spectrograms, labels, input_lengths, label_lengths\n",
        "    spectrograms.append(spec)\n",
        "    print(\"#>\", len(spectrograms))\n",
        "    label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "    print(utterance.lower())\n",
        "    print(text_transform.text_to_int(utterance.lower()))\n",
        "    #labels.append(label)\n",
        "    input_lengths.append(spec.shape[0]//2)\n",
        "    print(spec.shape)\n",
        "    print(spec.shape[0]//2)\n",
        "    #label_lengths.append(len(label))\n",
        "    print(len(label))\n",
        "\n",
        "\n",
        "    if inx == 5:\n",
        "        break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Vftj3hfdBD"
      },
      "source": [
        "# https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
        "\n",
        "learning_rate=5e-4\n",
        "batch_size=20\n",
        "epochs=10\n",
        "hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "model = SpeechRecognitionModel(\n",
        "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "print(model)\n",
        "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "oneWhat = next(iter(test_loader))\n",
        "#oneWhat = iter(test_loader)\n",
        "print(type(oneWhat))\n",
        "print(len(oneWhat))\n",
        "print([type(x) for x in oneWhat])\n",
        "print(oneWhat[0].size())\n",
        "print(oneWhat[1].size())\n",
        "print(oneWhat[2])\n",
        "print(sum(oneWhat[2]))\n",
        "print(oneWhat[3])\n",
        "print(sum(oneWhat[3]))\n",
        "\n",
        "#writer.add_graph(model, oneWhat)\n",
        "#writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}