{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Building an end-to-end Speech Recognition model in PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44d4cc1a27934239948b6584a776aa96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1f7304519d34890b8513f824b600861",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0e2f0e84a31456f8ef52b5cbdb8efa4",
              "IPY_MODEL_bdedfad0183b44afa6238992ea01c0eb"
            ]
          }
        },
        "d1f7304519d34890b8513f824b600861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0e2f0e84a31456f8ef52b5cbdb8efa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7637a4599e14c50b9fc1e8d48dbbbf4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 346663984,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 346663984,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a99acd50eed0458f93bd8653d7af995e"
          }
        },
        "bdedfad0183b44afa6238992ea01c0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d02eee2f980438eab2a61bb9a41cbbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:29&lt;00:00, 11.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98ba050f01c44737b7984aca296aedf5"
          }
        },
        "b7637a4599e14c50b9fc1e8d48dbbbf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a99acd50eed0458f93bd8653d7af995e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d02eee2f980438eab2a61bb9a41cbbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98ba050f01c44737b7984aca296aedf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TzurV/TestMe/blob/master/Understanding_Building_an_end_to_end_Speech_Recognition_model_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibD6bsRPl8Qu",
        "colab_type": "text"
      },
      "source": [
        "# Building an end-to-end Speech Recognition model in PyTorch - [AssemblyAI](https://www.assemblyai.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1fXgsDQmK09",
        "colab_type": "text"
      },
      "source": [
        "## installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfN8o17Bdp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "732191d1-9b73-491a-c643-226f4f158213"
      },
      "source": [
        "!pip install torchaudio==0.4.0 torch==1.4.0 comet-ml==3.0.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/bc/3ebc127162d27bed33dc914606f10117d106680baae7ce83603ea09985fd/torchaudio-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1MB 6.5MB/s \n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 753.4MB 23kB/s \n",
            "\u001b[?25hCollecting comet-ml==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/c6/fac88f43f2aa61a09fee4ffb769c73fe93fe7de75764246e70967d31da09/comet_ml-3.0.2-py3-none-any.whl (170kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.23.0)\n",
            "Collecting wurlitzer>=1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/24/5e/f3bd8443bfdf96d2f5d10097d301076a9eb55637b7864e52d2d1a4d8c72a/wurlitzer-2.0.0-py2.py3-none-any.whl\n",
            "Collecting netifaces>=0.10.7\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting everett[ini]>=1.0.1; python_version >= \"3.0\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (1.12.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (7.352.0)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.6.0)\n",
            "Collecting websocket-client>=0.55.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 43.0MB/s \n",
            "\u001b[?25hCollecting comet-git-pure>=0.19.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/7a/483413046e48908986a0f9a1d8a917e1da46ae58e6ba16b2ac71b3adf8d7/comet_git_pure-0.19.16-py3-none-any.whl (409kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419kB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (2020.4.5.2)\n",
            "Collecting configobj; extra == \"ini\"\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=1c3cce697f45bfcdaf8c73f1b2345ad9ddc58b343ac2f85f9c0bb7eb6aefddca\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "Successfully built configobj\n",
            "\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchaudio, wurlitzer, netifaces, configobj, everett, websocket-client, comet-git-pure, comet-ml\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "Successfully installed comet-git-pure-0.19.16 comet-ml-3.0.2 configobj-5.0.6 everett-1.0.2 netifaces-0.10.9 torch-1.4.0 torchaudio-0.4.0 websocket-client-0.57.0 wurlitzer-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSKHvy8DmOCQ",
        "colab_type": "text"
      },
      "source": [
        "## Setting up your data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJs4Bk8FjjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from comet_ml import Experiment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XdSlhAQnDEA",
        "colab_type": "text"
      },
      "source": [
        "## The Model\n",
        "Base of of Deep Speech 2 with some personal improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65H1-PCjm-FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuguNEzKnMOn",
        "colab_type": "text"
      },
      "source": [
        "## The Training and Evaluating Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydkqGeOwnPGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    with experiment.train():\n",
        "        for batch_idx, _data in enumerate(train_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            loss.backward()\n",
        "\n",
        "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
        "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            iter_meter.step()\n",
        "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(spectrograms), data_len,\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter, experiment):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with experiment.test():\n",
        "        with torch.no_grad():\n",
        "            for i, _data in enumerate(test_loader):\n",
        "                spectrograms, labels, input_lengths, label_lengths = _data \n",
        "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "                output = model(spectrograms)  # (batch, time, n_class)\n",
        "                output = F.log_softmax(output, dim=2)\n",
        "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "                test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "                for j in range(len(decoded_preds)):\n",
        "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "    experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
        "    experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
        "    experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "\n",
        "\n",
        "def main(learning_rate=5e-4, batch_size=20, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\",\n",
        "        experiment=Experiment(api_key='dummy_key', disabled=True)):\n",
        "\n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    experiment.log_parameters(hparams)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=28).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter, experiment)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBGdkQSmW3a",
        "colab_type": "text"
      },
      "source": [
        "## Setting up Comet\n",
        "If you have a comet account, fill in teh api key, project name and experiment name below. You can create an account at [comet.ml](comet.ml)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edo8shRBFt4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comet_api_key = \"\" # add your api key here\n",
        "project_name = \"speechrecognition\"\n",
        "experiment_name = \"speechrecognition-colab\"\n",
        "\n",
        "if comet_api_key:\n",
        "  experiment = Experiment(api_key=comet_api_key, project_name=project_name, parse_args=False)\n",
        "  experiment.set_name(experiment_name)\n",
        "  experiment.display()\n",
        "else:\n",
        "  experiment = Experiment(api_key='dummy_key', disabled=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxRIb_WempDq",
        "colab_type": "text"
      },
      "source": [
        "## GPU runtime\n",
        "If you are using a GPU runtime, this will let you know what GPU and how much memory is available. Adjust your batch_size depending on which GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlUSuAJwlzo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "81fafebf-f3b0-4545-fcb1-175c9704c7d4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 25 13:31:22 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7J9Gf4QtvNs",
        "colab_type": "text"
      },
      "source": [
        "# My learning code \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOlL3uB6t4ZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "44d4cc1a27934239948b6584a776aa96",
            "d1f7304519d34890b8513f824b600861",
            "d0e2f0e84a31456f8ef52b5cbdb8efa4",
            "bdedfad0183b44afa6238992ea01c0eb",
            "b7637a4599e14c50b9fc1e8d48dbbbf4",
            "a99acd50eed0458f93bd8653d7af995e",
            "4d02eee2f980438eab2a61bb9a41cbbd",
            "98ba050f01c44737b7984aca296aedf5"
          ]
        },
        "outputId": "aa0c3a8b-7b2e-4107-a7e9-e71a9969cad9"
      },
      "source": [
        "if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "        \n",
        "test_url=\"test-clean\"\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44d4cc1a27934239948b6584a776aa96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=346663984.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cei39GivZFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "99484cd1-075c-4bc9-dbf9-b0626ee09a4d"
      },
      "source": [
        "print(type(test_dataset))\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "print(use_cuda)\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=5, # originaly 20\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "print(type(test_loader))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchaudio.datasets.librispeech.LIBRISPEECH'>\n",
            "True\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIe3KLAwzgZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed0b3ba0-ee9b-45cb-b6ce-ed124eb98083"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "local_audio_transforms = nn.Sequential(\n",
        "    # https://pytorch.org/audio/transforms.html#melspectrogram\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128)#,\n",
        "    # https://pytorch.org/audio/transforms.html#frequencymasking\n",
        "    #torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    # https://pytorch.org/audio/transforms.html#timemasking\n",
        "    #torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "spectrograms = []\n",
        "labels = []\n",
        "input_lengths = []\n",
        "label_lengths = []\n",
        "\n",
        "inx = 0\n",
        "for (waveform, sample_rate, utterance, B, C, D) in test_dataset:\n",
        "    inx += 1\n",
        "    print(type(sample_rate))\n",
        "    print(type(B))\n",
        "    print(type(C))\n",
        "    print(type(D))\n",
        "    print(type(waveform))\n",
        "    print(type(utterance))\n",
        "    print(utterance)\n",
        "    print(f\"sample_rate={sample_rate} B={B} C={C} D={D}\")\n",
        "    \n",
        "    print(type(waveform))\n",
        "    print(\"Shape of waveform: {}\".format(waveform.size()))\n",
        "    print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
        "\n",
        "    if inx == 10:\n",
        "        # define 2 sub plots\n",
        "        fig, axs = plt.subplots(2)\n",
        "        #fig.suptitle('Vertically stacked subplots')\n",
        "        #axs[0].plot(x, y)\n",
        "        #axs[1].plot(x, -y)\n",
        "\n",
        "        #plt.figure()\n",
        "        axs[0].plot(waveform.t().numpy())  \n",
        "\n",
        "        spec = local_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        print(\"type(spec) is \", type(spec)) \n",
        "        print(\"Shape of spec: {}\".format(spec.size()))\n",
        "        #    axs[1].imshow(spec.log2().detach().numpy(), cmap='gray')\n",
        "        axs[1].imshow(torch.transpose(spec, 0, 1).log2().numpy(), cmap='gray')\n",
        "\n",
        "\n",
        "    # the 4 elements of the test_loader are defined by  def data_processing(..)\n",
        "    #           return  spectrograms, labels, input_lengths, label_lengths\n",
        "    spectrograms.append(spec)\n",
        "    label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "    print(utterance.lower())\n",
        "    print(text_transform.text_to_int(utterance.lower()))\n",
        "    #labels.append(label)\n",
        "    input_lengths.append(spec.shape[0]//2)\n",
        "    print(spec.shape)\n",
        "    print(spec.shape[0]//2)\n",
        "    #label_lengths.append(len(label))\n",
        "    print(len(label))\n",
        "\n",
        "\n",
        "    if inx == 5:\n",
        "        break\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'str'>\n",
            "IS IT BETTER THAN ANYWHERE ELSE\n",
            "sample_rate=16000 B=3729 C=6852 D=30\n",
            "<class 'torch.Tensor'>\n",
            "Shape of waveform: torch.Size([1, 45440])\n",
            "Sample rate of waveform: 16000\n",
            "is it better than anywhere else\n",
            "[10, 20, 1, 10, 21, 1, 3, 6, 21, 21, 6, 19, 1, 21, 9, 2, 15, 1, 2, 15, 26, 24, 9, 6, 19, 6, 1, 6, 13, 20, 6]\n",
            "torch.Size([228, 128])\n",
            "114\n",
            "31\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'str'>\n",
            "HE HIMSELF RECITED THE SAME PASSAGE IN FRENCH AND POLITELY POINTED OUT THE PARTS IN WHICH HE THOUGHT THAT I HAD IMPROVED ON THE ORIGINAL\n",
            "sample_rate=16000 B=3729 C=6852 D=39\n",
            "<class 'torch.Tensor'>\n",
            "Shape of waveform: torch.Size([1, 141200])\n",
            "Sample rate of waveform: 16000\n",
            "type(spec) is  <class 'torch.Tensor'>\n",
            "Shape of spec: torch.Size([707, 128])\n",
            "he himself recited the same passage in french and politely pointed out the parts in which he thought that i had improved on the original\n",
            "[9, 6, 1, 9, 10, 14, 20, 6, 13, 7, 1, 19, 6, 4, 10, 21, 6, 5, 1, 21, 9, 6, 1, 20, 2, 14, 6, 1, 17, 2, 20, 20, 2, 8, 6, 1, 10, 15, 1, 7, 19, 6, 15, 4, 9, 1, 2, 15, 5, 1, 17, 16, 13, 10, 21, 6, 13, 26, 1, 17, 16, 10, 15, 21, 6, 5, 1, 16, 22, 21, 1, 21, 9, 6, 1, 17, 2, 19, 21, 20, 1, 10, 15, 1, 24, 9, 10, 4, 9, 1, 9, 6, 1, 21, 9, 16, 22, 8, 9, 21, 1, 21, 9, 2, 21, 1, 10, 1, 9, 2, 5, 1, 10, 14, 17, 19, 16, 23, 6, 5, 1, 16, 15, 1, 21, 9, 6, 1, 16, 19, 10, 8, 10, 15, 2, 13]\n",
            "torch.Size([707, 128])\n",
            "353\n",
            "136\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'str'>\n",
            "HER FACE WAS AN ENIGMA FOR IT INSPIRED EVERYONE WITH THE WARMEST SYMPATHY AND YET IF YOU EXAMINED IT ATTENTIVELY THERE WAS NOT ONE BEAUTIFUL FEATURE SHE COULD NOT BE CALLED HANDSOME BUT NO ONE COULD HAVE THOUGHT HER UGLY\n",
            "sample_rate=16000 B=3729 C=6852 D=4\n",
            "<class 'torch.Tensor'>\n",
            "Shape of waveform: torch.Size([1, 263360])\n",
            "Sample rate of waveform: 16000\n",
            "her face was an enigma for it inspired everyone with the warmest sympathy and yet if you examined it attentively there was not one beautiful feature she could not be called handsome but no one could have thought her ugly\n",
            "[9, 6, 19, 1, 7, 2, 4, 6, 1, 24, 2, 20, 1, 2, 15, 1, 6, 15, 10, 8, 14, 2, 1, 7, 16, 19, 1, 10, 21, 1, 10, 15, 20, 17, 10, 19, 6, 5, 1, 6, 23, 6, 19, 26, 16, 15, 6, 1, 24, 10, 21, 9, 1, 21, 9, 6, 1, 24, 2, 19, 14, 6, 20, 21, 1, 20, 26, 14, 17, 2, 21, 9, 26, 1, 2, 15, 5, 1, 26, 6, 21, 1, 10, 7, 1, 26, 16, 22, 1, 6, 25, 2, 14, 10, 15, 6, 5, 1, 10, 21, 1, 2, 21, 21, 6, 15, 21, 10, 23, 6, 13, 26, 1, 21, 9, 6, 19, 6, 1, 24, 2, 20, 1, 15, 16, 21, 1, 16, 15, 6, 1, 3, 6, 2, 22, 21, 10, 7, 22, 13, 1, 7, 6, 2, 21, 22, 19, 6, 1, 20, 9, 6, 1, 4, 16, 22, 13, 5, 1, 15, 16, 21, 1, 3, 6, 1, 4, 2, 13, 13, 6, 5, 1, 9, 2, 15, 5, 20, 16, 14, 6, 1, 3, 22, 21, 1, 15, 16, 1, 16, 15, 6, 1, 4, 16, 22, 13, 5, 1, 9, 2, 23, 6, 1, 21, 9, 16, 22, 8, 9, 21, 1, 9, 6, 19, 1, 22, 8, 13, 26]\n",
            "torch.Size([707, 128])\n",
            "353\n",
            "220\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'str'>\n",
            "TWO YEARS BEFORE HER DEATH I SAW HER PERFORM THE CHARACTER OF MARIANNE IN THE COMEDY OF MARIVAUX AND IN SPITE OF HER AGE AND DECLINING HEALTH THE ILLUSION WAS COMPLETE\n",
            "sample_rate=16000 B=3729 C=6852 D=7\n",
            "<class 'torch.Tensor'>\n",
            "Shape of waveform: torch.Size([1, 199840])\n",
            "Sample rate of waveform: 16000\n",
            "two years before her death i saw her perform the character of marianne in the comedy of marivaux and in spite of her age and declining health the illusion was complete\n",
            "[21, 24, 16, 1, 26, 6, 2, 19, 20, 1, 3, 6, 7, 16, 19, 6, 1, 9, 6, 19, 1, 5, 6, 2, 21, 9, 1, 10, 1, 20, 2, 24, 1, 9, 6, 19, 1, 17, 6, 19, 7, 16, 19, 14, 1, 21, 9, 6, 1, 4, 9, 2, 19, 2, 4, 21, 6, 19, 1, 16, 7, 1, 14, 2, 19, 10, 2, 15, 15, 6, 1, 10, 15, 1, 21, 9, 6, 1, 4, 16, 14, 6, 5, 26, 1, 16, 7, 1, 14, 2, 19, 10, 23, 2, 22, 25, 1, 2, 15, 5, 1, 10, 15, 1, 20, 17, 10, 21, 6, 1, 16, 7, 1, 9, 6, 19, 1, 2, 8, 6, 1, 2, 15, 5, 1, 5, 6, 4, 13, 10, 15, 10, 15, 8, 1, 9, 6, 2, 13, 21, 9, 1, 21, 9, 6, 1, 10, 13, 13, 22, 20, 10, 16, 15, 1, 24, 2, 20, 1, 4, 16, 14, 17, 13, 6, 21, 6]\n",
            "torch.Size([707, 128])\n",
            "353\n",
            "167\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'str'>\n",
            "LET A MAN RUN AND EVERYBODY WILL RUN AFTER HIM THE CROWD WILL NOT STOP UNLESS THE MAN IS PROVED TO BE MAD BUT TO PROVE IT IS INDEED A DIFFICULT TASK BECAUSE WE HAVE A CROWD OF MEN WHO MAD FROM THEIR BIRTH ARE STILL CONSIDERED WISE\n",
            "sample_rate=16000 B=3729 C=6852 D=34\n",
            "<class 'torch.Tensor'>\n",
            "Shape of waveform: torch.Size([1, 302320])\n",
            "Sample rate of waveform: 16000\n",
            "let a man run and everybody will run after him the crowd will not stop unless the man is proved to be mad but to prove it is indeed a difficult task because we have a crowd of men who mad from their birth are still considered wise\n",
            "[13, 6, 21, 1, 2, 1, 14, 2, 15, 1, 19, 22, 15, 1, 2, 15, 5, 1, 6, 23, 6, 19, 26, 3, 16, 5, 26, 1, 24, 10, 13, 13, 1, 19, 22, 15, 1, 2, 7, 21, 6, 19, 1, 9, 10, 14, 1, 21, 9, 6, 1, 4, 19, 16, 24, 5, 1, 24, 10, 13, 13, 1, 15, 16, 21, 1, 20, 21, 16, 17, 1, 22, 15, 13, 6, 20, 20, 1, 21, 9, 6, 1, 14, 2, 15, 1, 10, 20, 1, 17, 19, 16, 23, 6, 5, 1, 21, 16, 1, 3, 6, 1, 14, 2, 5, 1, 3, 22, 21, 1, 21, 16, 1, 17, 19, 16, 23, 6, 1, 10, 21, 1, 10, 20, 1, 10, 15, 5, 6, 6, 5, 1, 2, 1, 5, 10, 7, 7, 10, 4, 22, 13, 21, 1, 21, 2, 20, 12, 1, 3, 6, 4, 2, 22, 20, 6, 1, 24, 6, 1, 9, 2, 23, 6, 1, 2, 1, 4, 19, 16, 24, 5, 1, 16, 7, 1, 14, 6, 15, 1, 24, 9, 16, 1, 14, 2, 5, 1, 7, 19, 16, 14, 1, 21, 9, 6, 10, 19, 1, 3, 10, 19, 21, 9, 1, 2, 19, 6, 1, 20, 21, 10, 13, 13, 1, 4, 16, 15, 20, 10, 5, 6, 19, 6, 5, 1, 24, 10, 20, 6]\n",
            "torch.Size([707, 128])\n",
            "353\n",
            "230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Vftj3hfdBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20830581-d6dc-401f-eff6-cb13387184df"
      },
      "source": [
        "# https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
        "\n",
        "learning_rate=5e-4\n",
        "batch_size=20\n",
        "epochs=10\n",
        "hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "model = SpeechRecognitionModel(\n",
        "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "print(model)\n",
        "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "oneWhat = next(iter(test_loader))\n",
        "#oneWhat = iter(test_loader)\n",
        "print(type(oneWhat))\n",
        "print(len(oneWhat))\n",
        "print([type(x) for x in oneWhat])\n",
        "print(oneWhat[0].size())\n",
        "print(oneWhat[1].size())\n",
        "print(oneWhat[2])\n",
        "print(sum(oneWhat[2]))\n",
        "print(oneWhat[3])\n",
        "print(sum(oneWhat[3]))\n",
        "\n",
        "#writer.add_graph(model, oneWhat)\n",
        "#writer.close()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SpeechRecognitionModel(\n",
            "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (rescnn_layers): Sequential(\n",
            "    (0): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (birnn_layers): Sequential(\n",
            "    (0): BidirectionalGRU(\n",
            "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): GELU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
            "  )\n",
            ")\n",
            "Num Model Parameters 23705373\n",
            "<class 'list'>\n",
            "4\n",
            "[<class 'torch.Tensor'>, <class 'torch.Tensor'>, <class 'list'>, <class 'list'>]\n",
            "torch.Size([5, 1, 128, 1512])\n",
            "torch.Size([5, 230])\n",
            "[114, 353, 658, 500, 756]\n",
            "2381\n",
            "[31, 136, 220, 167, 230]\n",
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXvlWZeVpXfX",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "this will download the data on first run and may take a while. \n",
        "\n",
        "If you have Comet.ml setup, you can start seeing your progress in the comet cell above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZodve8PGKfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set, experiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92kVVEr7GR6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucfQX3qN21az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}