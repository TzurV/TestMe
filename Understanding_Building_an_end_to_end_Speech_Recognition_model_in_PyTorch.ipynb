{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Building an end-to-end Speech Recognition model in PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44d4cc1a27934239948b6584a776aa96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1f7304519d34890b8513f824b600861",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0e2f0e84a31456f8ef52b5cbdb8efa4",
              "IPY_MODEL_bdedfad0183b44afa6238992ea01c0eb"
            ]
          }
        },
        "d1f7304519d34890b8513f824b600861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0e2f0e84a31456f8ef52b5cbdb8efa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7637a4599e14c50b9fc1e8d48dbbbf4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 346663984,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 346663984,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a99acd50eed0458f93bd8653d7af995e"
          }
        },
        "bdedfad0183b44afa6238992ea01c0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d02eee2f980438eab2a61bb9a41cbbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:29&lt;00:00, 11.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98ba050f01c44737b7984aca296aedf5"
          }
        },
        "b7637a4599e14c50b9fc1e8d48dbbbf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a99acd50eed0458f93bd8653d7af995e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d02eee2f980438eab2a61bb9a41cbbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98ba050f01c44737b7984aca296aedf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TzurV/TestMe/blob/master/Understanding_Building_an_end_to_end_Speech_Recognition_model_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibD6bsRPl8Qu",
        "colab_type": "text"
      },
      "source": [
        "# Building an end-to-end Speech Recognition model in PyTorch - [AssemblyAI](https://www.assemblyai.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1fXgsDQmK09",
        "colab_type": "text"
      },
      "source": [
        "## installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfN8o17Bdp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "732191d1-9b73-491a-c643-226f4f158213"
      },
      "source": [
        "!pip install torchaudio==0.4.0 torch==1.4.0 comet-ml==3.0.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/bc/3ebc127162d27bed33dc914606f10117d106680baae7ce83603ea09985fd/torchaudio-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1MB 6.5MB/s \n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 753.4MB 23kB/s \n",
            "\u001b[?25hCollecting comet-ml==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/c6/fac88f43f2aa61a09fee4ffb769c73fe93fe7de75764246e70967d31da09/comet_ml-3.0.2-py3-none-any.whl (170kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.23.0)\n",
            "Collecting wurlitzer>=1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/24/5e/f3bd8443bfdf96d2f5d10097d301076a9eb55637b7864e52d2d1a4d8c72a/wurlitzer-2.0.0-py2.py3-none-any.whl\n",
            "Collecting netifaces>=0.10.7\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting everett[ini]>=1.0.1; python_version >= \"3.0\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (1.12.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (7.352.0)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.6.0)\n",
            "Collecting websocket-client>=0.55.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 43.0MB/s \n",
            "\u001b[?25hCollecting comet-git-pure>=0.19.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/7a/483413046e48908986a0f9a1d8a917e1da46ae58e6ba16b2ac71b3adf8d7/comet_git_pure-0.19.16-py3-none-any.whl (409kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419kB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (2020.4.5.2)\n",
            "Collecting configobj; extra == \"ini\"\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=1c3cce697f45bfcdaf8c73f1b2345ad9ddc58b343ac2f85f9c0bb7eb6aefddca\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "Successfully built configobj\n",
            "\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchaudio, wurlitzer, netifaces, configobj, everett, websocket-client, comet-git-pure, comet-ml\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "Successfully installed comet-git-pure-0.19.16 comet-ml-3.0.2 configobj-5.0.6 everett-1.0.2 netifaces-0.10.9 torch-1.4.0 torchaudio-0.4.0 websocket-client-0.57.0 wurlitzer-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSKHvy8DmOCQ",
        "colab_type": "text"
      },
      "source": [
        "## Setting up your data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJs4Bk8FjjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from comet_ml import Experiment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XdSlhAQnDEA",
        "colab_type": "text"
      },
      "source": [
        "## The Model\n",
        "Base of of Deep Speech 2 with some personal improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65H1-PCjm-FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuguNEzKnMOn",
        "colab_type": "text"
      },
      "source": [
        "## The Training and Evaluating Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydkqGeOwnPGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    with experiment.train():\n",
        "        for batch_idx, _data in enumerate(train_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            loss.backward()\n",
        "\n",
        "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
        "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            iter_meter.step()\n",
        "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(spectrograms), data_len,\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter, experiment):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with experiment.test():\n",
        "        with torch.no_grad():\n",
        "            for i, _data in enumerate(test_loader):\n",
        "                spectrograms, labels, input_lengths, label_lengths = _data \n",
        "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "                output = model(spectrograms)  # (batch, time, n_class)\n",
        "                output = F.log_softmax(output, dim=2)\n",
        "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "                test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "                for j in range(len(decoded_preds)):\n",
        "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "    experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
        "    experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
        "    experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "\n",
        "\n",
        "def main(learning_rate=5e-4, batch_size=20, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\",\n",
        "        experiment=Experiment(api_key='dummy_key', disabled=True)):\n",
        "\n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    experiment.log_parameters(hparams)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=28).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter, experiment)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBGdkQSmW3a",
        "colab_type": "text"
      },
      "source": [
        "## Setting up Comet\n",
        "If you have a comet account, fill in teh api key, project name and experiment name below. You can create an account at [comet.ml](comet.ml)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edo8shRBFt4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comet_api_key = \"\" # add your api key here\n",
        "project_name = \"speechrecognition\"\n",
        "experiment_name = \"speechrecognition-colab\"\n",
        "\n",
        "if comet_api_key:\n",
        "  experiment = Experiment(api_key=comet_api_key, project_name=project_name, parse_args=False)\n",
        "  experiment.set_name(experiment_name)\n",
        "  experiment.display()\n",
        "else:\n",
        "  experiment = Experiment(api_key='dummy_key', disabled=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxRIb_WempDq",
        "colab_type": "text"
      },
      "source": [
        "## GPU runtime\n",
        "If you are using a GPU runtime, this will let you know what GPU and how much memory is available. Adjust your batch_size depending on which GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlUSuAJwlzo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "81fafebf-f3b0-4545-fcb1-175c9704c7d4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 25 13:31:22 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7J9Gf4QtvNs",
        "colab_type": "text"
      },
      "source": [
        "# My learning code \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOlL3uB6t4ZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "44d4cc1a27934239948b6584a776aa96",
            "d1f7304519d34890b8513f824b600861",
            "d0e2f0e84a31456f8ef52b5cbdb8efa4",
            "bdedfad0183b44afa6238992ea01c0eb",
            "b7637a4599e14c50b9fc1e8d48dbbbf4",
            "a99acd50eed0458f93bd8653d7af995e",
            "4d02eee2f980438eab2a61bb9a41cbbd",
            "98ba050f01c44737b7984aca296aedf5"
          ]
        },
        "outputId": "aa0c3a8b-7b2e-4107-a7e9-e71a9969cad9"
      },
      "source": [
        "if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "        \n",
        "test_url=\"test-clean\"\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44d4cc1a27934239948b6584a776aa96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=346663984.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cei39GivZFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "34ac2327-0e76-45cf-e1ff-e19b0fa5e102"
      },
      "source": [
        "print(type(test_dataset))\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "print(use_cuda)\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=20,\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "print(type(test_loader))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchaudio.datasets.librispeech.LIBRISPEECH'>\n",
            "True\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIe3KLAwzgZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "d7aeaa89-1e16-4569-e2b8-5e9c7652ab39"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "local_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128)#,\n",
        "    # https://pytorch.org/audio/transforms.html#frequencymasking\n",
        "    #torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    # https://pytorch.org/audio/transforms.html#timemasking\n",
        "    #torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "for (waveform, sample_rate, utterance, B, C, D) in test_dataset:\n",
        "    print(type(sample_rate))\n",
        "    print(type(B))\n",
        "    print(type(C))\n",
        "    print(type(D))\n",
        "    print(type(waveform))\n",
        "    print(type(utterance))\n",
        "    print(utterance)\n",
        "    print(f\"sample_rate={sample_rate} B={B} C={C} D={D}\")\n",
        "    \n",
        "    print(type(waveform))\n",
        "    print(\"Shape of waveform: {}\".format(waveform.size()))\n",
        "    print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "    #fig.suptitle('Vertically stacked subplots')\n",
        "    #axs[0].plot(x, y)\n",
        "    #axs[1].plot(x, -y)\n",
        "\n",
        "    #plt.figure()\n",
        "    axs[0].plot(waveform.t().numpy())  \n",
        "\n",
        "    spec = local_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "    print(\"type(spec) is \", type(spec)) \n",
        "    print(\"Shape of spec: {}\".format(spec.size()))\n",
        "    #    axs[1].imshow(spec.log2().detach().numpy(), cmap='gray')\n",
        "    axs[1].imshow(torch.transpose(spec, 0, 1).log2().numpy(), cmap='gray')\n",
        "\n",
        "    break\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'str'>\n",
            "IS IT BETTER THAN ANYWHERE ELSE\n",
            "sample_rate=16000 B=3729 C=6852 D=30\n",
            "<class 'torch.Tensor'>\n",
            "Shape of waveform: torch.Size([1, 45440])\n",
            "Sample rate of waveform: 16000\n",
            "type(spec) is  <class 'torch.Tensor'>\n",
            "Shape of spec: torch.Size([228, 128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Vftj3hfdBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ac5fccd-746e-4139-a95f-d3c54605054c"
      },
      "source": [
        "# https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
        "\n",
        "learning_rate=5e-4\n",
        "batch_size=20\n",
        "epochs=10\n",
        "hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "model = SpeechRecognitionModel(\n",
        "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "print(model)\n",
        "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "oneWhat = next(iter(test_loader))\n",
        "#oneWhat = iter(test_loader)\n",
        "print(type(oneWhat))\n",
        "print(len(oneWhat))\n",
        "print([type(x) for x in oneWhat])\n",
        "print(oneWhat[0].size())\n",
        "print(oneWhat[1].size())\n",
        "print(oneWhat[2])\n",
        "print(oneWhat[3])\n",
        "\n",
        "#writer.add_graph(model, oneWhat)\n",
        "#writer.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SpeechRecognitionModel(\n",
            "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (rescnn_layers): Sequential(\n",
            "    (0): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (birnn_layers): Sequential(\n",
            "    (0): BidirectionalGRU(\n",
            "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): GELU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
            "  )\n",
            ")\n",
            "Num Model Parameters 23705373\n",
            "<class 'torch.utils.data.dataloader._MultiProcessingDataLoaderIter'>\n",
            "131\n",
            "[<class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2ebb7cc1114e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneWhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moneWhat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneWhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneWhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneWhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '_MultiProcessingDataLoaderIter' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXvlWZeVpXfX",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "this will download the data on first run and may take a while. \n",
        "\n",
        "If you have Comet.ml setup, you can start seeing your progress in the comet cell above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZodve8PGKfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set, experiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92kVVEr7GR6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucfQX3qN21az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}